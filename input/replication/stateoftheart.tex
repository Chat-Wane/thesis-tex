

\section{État de l'art}
\label{repl:sec:stateoftheart}

Dès 1975, les bases de données répliquées font leur
apparition~\cite{johnson1975maintenance} afin de résoudre
\begin{inparaenum}[(i)]
\item les problèmes de défaillances~\cite{alsberg1976principle}, i.e., le
  serveur possédant les données étant inaccessible, le client peut contacter
  serveur alternatif connu pour posséder les mêmes données afin de satisfaire sa
  requête;
\item les problèmes de rapidité d'accès, i.e., le client peut contacter un
  serveur avec lequel la latence est faible afin de satisfaire plus rapidement
  sa requête.
\end{inparaenum}

Cependant la réplication introduit un nouveau type de problèmes : la
synchronisation des répliques. En effet, puisque la communication entre serveurs
n'est pas instantanée, les modifications effectuées sur les données prennent du
temps à parvenir aux répliques. Cela implique des problèmes de
\begin{inparaenum}[(i)]
\item fraîcheur de données -- \emph{est-ce que la donnée que j'obtiens est la
    plus à jour ?} -- et de
\item modifications concurrentes -- \emph{avec des modifications effectuées sur
    une même données, au même moment, par deux serveurs distants dont les
    résultats sont différents. Dois-je conserver les deux modifications, ou
    dois-je en privilégier une, ou dois-je employer une autre stratégie ?}
\end{inparaenum}


D'après le théorème CAP~\cite{brewer2012cap, gilbert2002brewer} il est
impossible de répliquer sur un grand nombre de serveurs tout en garantissant la
cohérence forte~\cite{herlihy1990linearizability}, la disponibilité, et la
tolérances aux partitionnements. Dans ce manuscrit, nous nous intéressons aux
applications garantissant ces deux dernières propriétés. Ainsi, une opération
est toujours acceptée par le système. De plus, le système, constitué de
plusieurs serveurs distants, autorise la fragmentation temporairement en
ilôts. Par conséquent, le critère de cohérence doit être
affaiblit~\cite{bailis2013eventual, shapiro2011conflict}.

Le reste de cette section décrit le schéma garantissant les deux propriétés
recherchées, à savoir la réplication optimiste (cf. §\ref{repl:subsec:optimistic}).
Ensuite, elle passe en revue deux familles d'approches appartenant à la
réplication optimiste : les transformées opérationnelles et les structures de
données répliquées sans résolution de conflits
(cf. §\ref{repl:subsec:otorcrdts}). Enfin, nous nous intéresserons plus
particulièrement aux types de données représentant les séquences -- la séquence
de caractères étant proche d'un document (cf. §\ref{repl:subsec:sequences}). 

% \subsection{Pessimisme ou optimisme ?}
% \label{repl:subsec:schemas}

% De multiples serveurs, possiblement distants les uns des autres, hébergent une
% réplique d'une donnée. Lorsqu'une réplique est modifiée, sa modification est
% répercutée sur les autres répliques. Les deux schémas de réplication définissent
% la manière dont une modification est acceptée. Cela influe sur les propriétés du
% système. En particulier, les dimensions que peuvent atteindre les systèmes, en
% nombre de répliques, s'en trouve impactées.

% \subsubsection{Réplication pessimiste}
% \label{repl:subsubsec:pessimistic}

% L'objectif de la réplication pessimiste est simple. Il consiste à donner
% l'illusion que la donnée manipulée est unique, indépendemment du nombre de
% répliques réel. Ainsi, il devient facile de raisonner sur les données puisque
% leurs spécifications sont proches de celles proposées dans un contexte sans
% réplications.  Toutefois, avant qu'une modification ne soit réellement
% effectuée, il est nécessaire qu'elle soit validée. L'autorité décisionnelle
% diffère en fonction des approches :

% \paragraph{Autorité centrale~\cite{alsberg1976principle} :} Un serveur est
% désigné responsable. Ceux qui souhaitent modifier la donnée sont alors dans
% l'obligation de demander l'accès exclusif pendant la mise en place de cette
% modification. Dans l'intervalle, les autres répliques ne peuvent soumettre de
% modifications. Enfin, lorsque la modification est achevée, la main est rendue au
% serveur qui peut autoriser d'autres modifications. On parle de verrou
% (\emph{lock}).

% \paragraph{Quorum~\cite{gifford1979weighted} :} Un ensemble de serveurs est
% désigné responsable. Chacune des modifications est soumise à un vote quant à son
% acceptation. Au dessus d'un certain seuil de vote positif ou négatif, la
% modification est autorisée ou non.



% \begin{figure*}
%   \centering
%   \subfloat[Une demande de modification est effectuée]
%   [Le serveur $n_5$ demande au cœur décisionnel si sa modification est acceptée.]
%   {\input{./input/replication/figpessimisticexampleA.tex}}
%   \hspace{40pt}
%   \subfloat[Une autre demande est faite pendant que le cœur s'occupe de 
%   la première demande]
%   [Le serveur $n_4$ demande également si sa modification est acceptée pendant
%   que le cœur est occupé avec la modification de $n_5$.]
%   {\input{./input/replication/figpessimisticexampleB.tex}}
%   \hspace{10pt}
%   \subfloat[Une modification est acceptée pendant que l'autre est refusée]
%   [La modification de $n_5$ est acceptée tandis que celle de $n_4$ 
%   est refusée.]
%   {\input{./input/replication/figpessimisticexampleC.tex}}
%   \caption[Quorum en réplication pessimiste]
%   {\label{repl:fig:pessimisticexample} Exemple de quorum en réplication
%     pessimiste. La modification de $n_5$ est propagée.}
% \end{figure*}

% La figure~\ref{repl:fig:pessimisticexample} montre un exemple de réplication
% pessimiste où le cœur décisionnel est composé de 3 serveurs
% $\{n_1,\, n_2,\, n_3\}$ devant unanimement approuver une modification avant
% qu'elle soit propagée. Ainsi, le serveur $n_5$ propose une modification des
% répliques au cœur décisionnel via $n_1$. Ce dernier l'accepte et transmet la
% demande à $n_2$, qui l'accepte et la transmet à son tour à $n_3$, qui l'accepte
% et termine la boucle en transmettant à $n_1$.  Dans l'intervalle, $n_4$ propose
% une autre modification. La proposition de $n_5$ est acceptée et propagée tandis
% que celle de $n_4$ est refusée. Une fois que $n_4$ a reçu les modifications de
% $n_5$, il peut retenter de transmettre sa modification s'il la juge toujours
% d'actualité. Cet exemple illustre le caractère chronophage du processus : le
% vote prend du temps et peut échouer. De plus, si l'un des serveurs du cœur
% défaillit, le vote peut échouer alors même que la modification est valide.

% La réplication pessimiste est possible lorsque le nombre de répliques est connu,
% plutôt petit, et souvent accessible. Ces contraintes sont notamment
% satisfaisable dans le Nuage~\cite{mell2011national}. Les répliques proposent
% d'avantage de garanties quant aux résultats de la manipulation des
% données. Toutefois, de telles garanties ne sont pas toujours nécessaires et
% leur coût élevé n'est plus justifié. La réplication optimiste constitue alors
% une alternative possible.

\subsection{La réplication optimiste}
\label{repl:subsec:optimistic}

En 1987, Demers et al. décrivent une base de données répliquée sur plusieurs
centaines de machines pouvant communiquer entre elles au travers de matériels
aux capacités hétérogènes~\cite{demers1987epidemic}. Du fait de ces dimensions,
la réplication pessimiste~\cite{alsberg1976principle, gifford1979weighted}, où
les opérations doivent être approuvées avant d'être appliquées, semble
impossible.

La réplication optimiste~\cite{demers1987epidemic, johnson1975maintenance,
  ladin1992providing, saito2005optimistic} est un paradigme de réplication
consistant à appliquer les modifications directement sur une réplique locale.
Ainsi, les données sont toujours disponibles et réactives aux changements
effectués. Ensuite, les modifications sont disséminées aux autres serveurs
hébergeant une réplique où elles sont appliquées. Au contraire des approches
pessimistes, les approches optimistes ne verrouillent pas les données lors des
changements. En revanche, le critère de cohérence assuré est plus faible. En
particulier, les répliques peuvent être temporairement dans des états
divergeant entre eux :


\paragraph{Cohérence à terme~\cite{bailis2013eventual} :} Lorsque toutes les
modifications ont été reçues et intégrées par toutes les répliques, celles-ci
possèdent un état équivalent.

\noindent Puisque ``\emph{toutes} les modifications'' constitue un ensemble peu
réaliste pour raisonner sur une exécution réelle, une définition plus précise
porte sur un sous-ensemble de ces modifications :

\paragraph{Cohérence forte à terme~\cite{shapiro2011conflict} :} Les répliques
ayant reçu et intégré les mêmes modifications possèdent un état équivalent.


\begin{figure*}
  \centering
  \subfloat[Modifications concurrentes]
  [Les serveurs $n_1$ et $n_3$ modifient leur couleur en même temps.]
  {\input{./input/replication/figoptimisticexampleA.tex}}
  \hspace{10pt}
  \subfloat[Plusieurs états possibles]
  [Les répliques convergent. Plusieurs états de convergence sont possibles.]
  {\input{./input/replication/figoptimisticexampleB.tex}}
  \caption[Convergence en réplication optimiste]
  {\label{repl:fig:optimisticexample} Exemple de réplication optimiste avec
    modifications concurrentes.}
\end{figure*}


Ces critères de cohérence posent de nombreux problèmes par leur trop grande
expressivité. En particulier, l'état équivalent vers lequel les répliques
convergent n'est pas spécifié. Le type de données répliqué doit respecter autant
que possible la spécification de sa version
séquentielle~\cite{bieniusa2012brief}. Cependant, résoudre les cas concurrents
reste à la charge des développeurs. La figure~\ref{repl:fig:optimisticexample}
montre un exemple où les répliques concernent une couleur. Le serveur $n_1$
souhaite une couleur bleu tandis que $n_3$ souhaite une couleur blanche. Après
échange, une infinité d'états convergeants sont possibles. Par exemple, l'état
(i) et (ii) privilégient une seule des modifications. L'état (iii) tente de
réconcilier les deux modifications en mélangeant les couleurs pour obtenir un
bleu plus clair. L'état (iv) est un état arbitraire sans signification
réelle. Tous ces choix respectent la cohérence forte à terme, même celui de
l'état arbitraire.

Ce type de cohérence charge le développeur d'un poids énorme quant au bien fondé
de l'état convergeant.  Récemment, de nombreux efforts ont été fournis afin de
proposer des bases de données avec cohérence à terme~\cite{dynamo, riak,
  cassandra, mongodb}, ainsi que des langages sur lesquels
raisonner~\cite{conway2012logic, meiklejohn2015lasp}.
% La section~\ref{repl:subsec:otorcrdts} décrit les approches permettant de
% construire ces bases et langages.


\subsection{Transformations ou commutativité ?}
\label{repl:subsec:otorcrdts}

La réplication optimiste consiste à maintenir une copie locale des
données. Chaque modification locale est immédiatement appliquée et disséminée
aux autres serveurs possédant la réplique. Grâce à cela, les données sont
toujours disponibles et réactives aux changements. Toutefois, les approches
appartenant à ce schéma de réplication doivent fournir des opérations respectant
la cohérence à terme. Cette section décrit deux familles d'approches : les
approches à transformées opérationnelles (cf. §\ref{repl:subsubsec:ot}) et les
approches à structure de données répliquées sans résolution de conflits
(cf. §\ref{repl:subsubsec:crdts}) ainsi que le coût qui leur est associé.

\subsubsection{Transformées opérationnelles}
\label{repl:subsubsec:ot}

Les approches basées sur les transformées
opérationnelles~\cite{sun1998operational, sun2009contextbased} (OT) sont les
plus anciennes et s'appliquent à un large champs d'applications telles que
l'édition de texte, ou l'édition d'images. L'intuition est simple : lors de la
réception d'opérations modifiant une réplique, ses arguments sont ajustés afin
qu'ils s'appliquent à l'état actuel de la réplique, malgré des opérations qui
furent effectuées en concurrence et qui sont déjà intégrées.

\begin{figure}
  \centering
  \input{./input/replication/figotexample.tex}
  \caption[Exemple de transformé opérationnel] {\label{repl:fig:otexample}
    Exemple de transformé opérationnel. L'opération de suppression des 3
    premiers caractères sur la réplique 3 (\texttt{RTY}) est transformée afin de
    supprimer les 3 derniers caractères sur les autres répliques.}
\end{figure}

La figure~\ref{repl:fig:otexample} illustre le principe de fonctionnement des
approches basées sur les transformés opérationnels sur un scénario impliquant
une séquence répliquée. Dans cet exemple, les répliques sont toutes initialisées
avec la séquence \texttt{RTY}. Ensuite, tandis que sur la première réplique
trois caractères supplémentaires sont insérés en tête pour obtenir
\texttt{QWERTY}, sur la troisième réplique sont supprimés les trois caractères
pour obtenir la séquence vide. Lors de la réception de cette dernière opération
de suppression au niveau de la réplique 1, elle est interprétée comme une
opération dont le contexte d'exécution n'avait pas encore intégré les insertions
-- et donc pas décalé les indices des caractères. À ce titre, l'argument de
l'opération voit sa cible changée aux trois caractères à partir du troisième
caractère exclu. Réciproquement, la réplique 3 intègre les insertions faites sur
la réplique 1. Toutefois aucun changement n'est nécessaire. À terme, les
répliques convergent vers la séquence \texttt{QWE}.

Dans le cadre de l'édition de texte, en plus des usuelles opérations d'insertion
et de suppression, OT fournit des opérations ciblant les chaînes de caractères
telles que le déplacement, ou le couper -- coller. Toutefois, l'analyse de
correction nécessite d'examiner chaque couple d'opérations ainsi que leurs
paramètres. En conséquence, lors de l'écriture du
papier~\cite{imine2003proving}, peu d'approches étaient réellement correctes.
De plus, Joseph Gentle, l'un des ingénieurs ayant participé au développement de
\emph{Google Wave}~\cite{googlewave, kaewkitipong2012diffusion} a déclaré que la
complexité de OT avait conduit à 2 ans de développement, et que 2 ans seraient à
nouveau nécessaire s'il fallait recommencer son développement.

\noindent Les approches OT peuvent être divisées en deux classes :

\paragraph{Les approches décentralisées~\cite{sun2009contextbased} :}
Chaque client est aussi un serveur hébergeant une réplique
(cf. figure~\ref{repl:fig:otexample}). Chacune de ces entités doit être en
mesure d'effectuer les transformations d'elle-même. Parmi les pré-requis à cette
tâche figure le mécanisme de détection de concurrence. En effet, retrouver le
contexte d'exécution revient à transformer l'opération reçu contre toutes celles
qui ont été intégrées sans avoir connaissance de celle-ci. Malheureusement, cela
requière le transport d'un vecteur d'horloges (\emph{vector
  clock})~\cite{lamport1978time} ou de contexte avec chaque opération, qui sont
ensuite sauvegardés dans un historique d'opérations. Que ce soit en terme de
nombre d'utilisateurs ou en terme de nombre d'opérations, ces approches passent
difficilement à l'échelle. Le temps d'exécution d'une opération locale est
insignifiant, mais tout le reste des participants souffrent de quelques
opérations concurrentes.

\noindent Du reste, dans un environnement bien maîtrisé, où les opérations
arrivent très rapidement à un groupe raisonnable de participants, alors ces
approches décentralisées deviennent extrêmement
efficaces~\cite{mehdi2014merging}.

\paragraph{Les approches centralisées~\cite{nichols1995high} :} Elles utilisent
un serveur central afin de réarranger et diffuser les opérations de tous les
participants à tous les participants. La transformation s'en trouve beaucoup
moins coûteuse dès lors qu'un serveur participe au processus. Toutefois, la
topologie elle-même implique plusieurs défauts, à savoir, des problèmes
concernant la confidentialité (celui à qui appartient le serveur possède les
données), des problèmes concernant le passage à l'échelle (le serveur supporte
la charge de tous les participants) et des problèmes de tolérance aux pannes (le
serveur constitue un point unique de défaillance).

\noindent Malgré tous ces défauts, les approches centralisées sont les plus
courantes aujourd'hui avec, notamment, les éditeurs web bien connus tels que
Google Docs~\cite{googledocs} ou Etherpad~\cite{etherpad}.


\subsubsection{Structure de données répliquée sans résolutions de conflits}
\label{repl:subsubsec:crdts}

Un conflit peut apparaître lorsqu'une valeur particulière est modifiée en
concurrence. Par exemple, la figure~\ref{repl:fig:optimisticexample} montre un
conflit sur le choix de la couleur. Les auteurs des modifications ayant pris
connaissance de ce conflit peuvent s'arranger afin de ne garder que l'une des
valeurs. Dans tous les cas, la résolution de conflits prend du temps, est
susceptible d'engendrer des erreurs, ou d'autres conflits en cascade.

Les structures de données répliquées sans résolution de conflits
(CRDTs)~\cite{shapiro2011comprehensive, shapiro2011conflict} appartiennent au
schéma de réplication optimiste. Comme leur dénomination l'indique, ces
approches sont basées sur des structures de données abstraites fournissant des
opérations dont les résultats commutent, et donc, ne génèrent pas de conflits,
même en cas de concurrence.  Il en existe trois familles équivalentes mais
proposant un compromis différent :

\paragraph{Basée sur l'état :} Lors d'une opération, l'état local change et est
envoyé en totalité aux autres répliques qui fusionnent alors l'état reçu et leur
état propre. L'envoi d'un état est onéreux et doit être effectué avec
parcimonie. En revanche, puisqu'il est autonome (\emph{self-contained}), il ne
nécessite aucune garantie particulière quant aux moyens de diffusion.

\noindent La structure doit proposer une opération de fusion qui est commutative
($o_1 \times o_2 \Leftrightarrow o_2 \times o_1$), associative
($(o_1 \times o_2) \times o_3 \Leftrightarrow o_1 \times (o_2 \times o_3)$) et
idempotente ($o_1 \times o_1 \Leftrightarrow o_1$).

\paragraph{Basée sur les opérations :} Lors d'une opération, son résultat seul
est envoyé aux autres répliques où il est intégré. Les résultats sont envoyés
les uns après les autres ce qui s'avère beaucoup moins coûteux que l'état
complet. En revanche, cela requière une diffusion fiable, i.e., toutes les
opérations doivent être inéluctablement reçues par tous les serveurs hébergeant
une réplique.

\noindent Les opérations doivent également être commutatives, associatives et
idempotentes.

\paragraph{Basée sur les différences~\cite{vanderlinde2016delta} :} Lors d'une
opération, l'état de la réplique locale change. Un vecteur d'horloges permet
d'identifier chacune des opérations effectuées. Une autre réplique envoie alors
son vecteur à cette première. Les différences entre les vecteurs permettent
d'identifier les opérations manquantes avant de les envoyer. Comparé aux
approches basées sur l'état, l'ensemble de la réplique n'a pas besoin d'être
systématiquement envoyé. Comparé aux approches basées sur les opérations, le
réseau n'a pas de propriétés particulières à assurer.

{\noindent%
\begin{minipage}[t]{0.48\textwidth}
  \begin{algorithm}[H]
    \input{input/replication/algocounterA.tex}
    \caption[Compteur utilisant un ensemble]
    {\label{repl:algo:counterA} Compteur utilisant un ensemble.}
  \end{algorithm}
\end{minipage}%
\hfill%
\begin{minipage}[t]{0.48\textwidth}
  \begin{algorithm}[H]
    \input{input/replication/algocounterB.tex}
    \caption[Compteur utilisant un vecteur]
    {\label{repl:algo:counterB} Compteur utilisant un vecteur.}
  \end{algorithm}
\end{minipage}
} \\

Des CRDTs existent pour différent types de structures tels que les compteurs,
les ensembles, ou les graphes. Les algorithmes~\ref{repl:algo:counterA}
et~\ref{repl:algo:counterB} décrivent le squelette des algorithmes CRDTs divisé
selon le schéma de réplication optimiste, et selon le principe des CRDTs basés
sur les opérations. Ils prennent l'exemple simple des compteurs.

L'algorithme~\ref{repl:algo:counterA} présente une première façon d'implémenter
un CRDT pour compteur basé sur les opérations. Celle-ci associe un identifiant
unique à chaque opération d'incrémentation. Cet identifiant est composé de
l'identité unique du serveur et d'un compteur local. À chaque opération
d'incrémentation. Dans le cas du compteur n'autorisant que les incrémentations,
ces identifiants seuls permettent de garantir l'idempotence pour peu qu'ils
soient enregistrés. Ainsi, un ensemble enregistre les identifiants des
opérations. En cas de double réception due aux aléas du réseau, la seconde
intégration est sans effets. L'ordre de réception des opérations est sans
importance puisque l'effet de l'unique opération possible est toujours le
même. Lire la valeur courante de ce compteur revient à effectuer le cardinal de
l'ensemble des identifiants.

Cette approche est simple mais ne tire pas profit de la redondance
d'informations contenue dans les identifiants. En particulier, si un serveur
génère un identifiant $\langle n,\, c\rangle$ c'est qu'il fût incrémenté $c-1$
fois par le passé. Ainsi, seule la plus haute valeur
compte. L'algorithme~\ref{repl:algo:counterB} montre les instructions d'un tel
compteur. À la différence du premier algorithme, la structure utilisée est un
vecteur d'entrées où chaque site se voit attribué son compteur connu. La valeur
du compteur est alors la somme des compteurs de ce vecteur.

La complexité en communication des deux algorithmes est identique : elle est
constante. La complexité en temps est identique sauf pour la fonction
\textsc{query} où le second algorithme itère sur les identifiants du vecteur
afin de retourner la valeur du compteur. Toutefois, au prix d'un entier
supplémentaire pour sauvegarder la taille totale, les complexités temporelles
sont équivalentes. Enfin, lorsque le premier algorithme possède une complexité
spatiale bornée linéairement au nombre d'incrémentations, le second algorithme
possède une complexité spatiale bornée linéairement au nombre de sites. Par
conséquent, l'algorithme~\ref{repl:algo:counterB} domine
l'algorithme~\ref{repl:algo:counterA}. La section~\ref{repl:subsec:sequences}
décrit les approches CRDTs destinées aux séquences. Hélas, l'analyse en
complexité s'avère plus difficile et souvent moins tranchée que dans l'exemple
des compteurs.


\subsection{Séquences répliquées}
\label{repl:subsec:sequences}

Une séquence\footnote{ou liste, ou tableau, ou série} est une série d'éléments
ordonnés les uns à la suite des autres. Une séquence répliquée doit donc
ordonner de la même manière ses éléments quel que soit le serveur
l'hébergeant. Les approches à base de transformées opérationnelles adaptent les
arguments des opérations afin de recouvrer un contexte d'exécution valide
(cf. §\ref{repl:subsubsec:ot}). Les CRDTs pour séquences, eux, choisissent de
surcharger les éléments avec des métadonnées de telle sorte que les métadonnées
permettent de recouvrer un ordre identique partout. Une différence fondamentale
entre les deux types d'approches concerne la signature des opérations. Lorsque
OT conserve une signature d'opération classique (``insérer l'élément $e$ à
l'indice $i$''), les CRDTs positionnent leurs éléments relativement aux éléments
adjacents à l'indice ciblé (``insérer l'élément $e$ entre l'élément $a$ et
l'élément $b$''). Avec ce procédé, des métadonnées uniques et non-mutables --
nommées identifiants -- sont générées garantissant, grâce à un ordre total sur
ceux-ci, que le nouvel élément est bel et bien placé entre ces deux bornes. La
suppression est également différente puisque sa signature devient l'élément
ciblé et non plus un indice (``supprimer l'élément $e$'').

Nous identifions deux familles d'approches appartenant aux CRDTs conçues pour
les séquences. La première génère des identifiants de taille constante mais
utilise des pierres tombales pour indiquer la suppression d'un élément. La
seconde se passe de pierres tombales mais ses identifiants sont de taille
variable lors de la génération

\subsubsection{Pierres tombales}

Une pierre tombale est une marque laissée après la suppression d'un élément
indiquant qu'un jour, celui-ci a existé, et qu'il était positionné là. Bien
entendu, ces marques sont cachées à l'utilisateur et n'apparaissent que dans la
structure sous-jacente. L'impact sur les performances en reste néanmoins
présent.

\paragraph{WOOT~\cite{oster2006data} :} Le premier représentant historique des
CRDTs pour séquences suivi par deux extensions
\textbf{WOOTO~\cite{weiss2007wooki}} et
\textbf{WOOTH~\cite{ahmed2011evaluating}}. Dans cette approche chaque
identifiant fait référence aux identifiants voisins à l'insertion.  Lorsqu'ils
sont rassemblés, les identifiants peuvent être ordonnés grâce à un diagramme de
Hasse. Toutefois, cet ordonnancement requiert des deux bornes adjacentes
qu'elles soient
\begin{inparaenum}[(i)]
\item déjà intégrées et
\item toujours présentes.
\end{inparaenum}
D'où les suppressions réelles impossibles.

\begin{figure}
  \centering
  \input{input/replication/figwootexample.tex}
  \caption[Diagramme de Hasse dans WOOT]
  {\label{repl:fig:wootexample}Le diagramme de Hasse du modèle WOOT représentant
    la séquence \texttt{QWERTY}. Bien que supprimé, le caractère \texttt{Z} est
    indispensable au bon ordonnancement de la séquence.}
\end{figure}

\noindent La figure~\ref{repl:fig:wootexample} illustre la nécessité de
conserver les pierres tombales. Elle montre le diagramme de Hasse généré lors du
scénario suivant. Tout d'abord, un utilisateur écrit \texttt{AZERTY}. Ensuite,
les deux premiers caractères sont supprimés afin d'être remplacés par les
caractères \texttt{QW}. La séquence finale est \texttt{QWERTY}. Toutefois, les
identifiants ne sont pas modifiables, et l'identifiant du caractère \texttt{E}
référence l'identifiant de \texttt{Z}, lui-même référençant l'identifiant de
\texttt{A}. Par conséquent, supprimer complètement les identifiants de
\texttt{A} et/ou de \texttt{Z} revient à rendre l'identifiant de \texttt{E} non
positionnable, et tout ceux qui en dépendent par transitivité.

\paragraph{Causal tree~\cite{grishchenko2010deep} :} Cette approche caractérise
explicitement les relations causales grâce à une représentation sous forme
d'arbre. Ainsi, chaque opération est accompagnée de l'identifiant de la dernière
opération observée. En parcourant l'arbre et en appliquant les opérations, la
séquence peut être retrouvée. Toutefois, les identifiants sont des horloges
vectorielles (\emph{vector clock}) dont la taille est prohibitive. De plus, il
est nécessaire de conserver tous les noeuds de cet arbre causal au cas où une
opération y ferait référence.

\paragraph{Partial persistent séquence~\cite{wu2010partial} :} Cette approche
définit les identifiants dans l'ensemble des nombres rationnels auxquels est
ajoutée une limite quant à leur précision. Hélas, cette limite contraint la
taille du document maximale. Sans cette troncature, l'approche serait
susceptible d'appartenir à l'autre famille de CRDTs pour séquence.

\paragraph{Replicated growable array~\cite{roh2011replicated} :} Cette structure
représente la séquence sous forme de liste supportant les opérations
concurrentes. Une table de hachage apporte un accès rapide aux éléments grâce à
leurs identifiants. Les éléments incluent une référence au voisin qu'ils
précèdent lors de leur insertion. Toutefois, pour ne jamais briser la chaîne
ainsi construite, les éléments supprimés restent présents à tout jamais
quoique cachés de l'utilisateur. Une variante sous forme d'arbre a récemment été
proposée~\cite{attiya2016specification}.

\paragraph{String-wise~\cite{yu2012stringwise} :} Cette approche cible
principalement les chaînes de caractères pouvant être subdivisées lors
d'opérations jusqu'à devenir une série de caractères. Les identifiants
référencent alors les chaînes adjacentes à l'insertion ainsi que les autres
éléments de la chaînes si subdivision il y a. De la même manière que pour les
approches précédentes, les références rendent les suppressions réelles
impossibles.

\paragraph{DiCE~\cite{conway2014language} :} Cet éditeur concentre
principalement ses efforts sur les garanties de confluence de la
séquence. Chaque identifiant référence le voisin qu'il précède à
l'insertion. L'ordre des éléments est alors fonction de ces relations de
positionnement relatif, et de causalité.


Bien que l'accent soit mit sur l'impossibilité de réellement supprimer les
éléments de séquences répliquées, toutes ces approches restent utiles lorsque
l'historique des opérations doit être conservé. Par exemple, dans le cadre de
l'encyclopédie \emph{Wikipédia}~\cite{wikipedia}, conserver toutes les
modifications effectuées permet de recouvrer une version vierge de vandalisme;
dans le cadre du gestionnaire de versions \emph{Git}~\cite{git}, il permet de
recouvrer une version du code potentiellement sans erreurs. Cependant, ces
structures grandissent au moins linéairement comparativement au nombre
d'opérations faites sur la séquence. Paradoxalement, cela devient problématique
lors de vandalisme où même le contenu indésirable est conservé
à tout jamais. Survient alors le frustrant constat d'avoir à stocker un
fichier dont le poids ne reflète pas le contenu visible. De plus, les éléments
cachés s'accumulent et dégradent à jamais les performances du système.

Lorsque conserver l'historique ne constitue pas une contrainte, purger la
structure de données des éléments cachés est une solution potentielle aux
dégradations de performances :

\paragraph{ramasse-miettes~\cite{abdullahi1998garbage} :} permet de nettoyer une
structure de données en vidant de la mémoire les objets qui ne sont plus
accessibles par le programme. Le contexte réparti étend le cadre du programme en
considérant le local et le distant. Ainsi, supprimer réellement un élément de la
séquence revient à s'interroger : \emph{Est-ce que
  \begin{inparaenum}[(i)]
  \item toutes les répliques ont supprimé l'élément et
  \item tous les éléments référençant l'élément supprimé ont été intégrés
    localement ?
  \end{inparaenum}} Cela va sans dire qu'il est difficile d'apporter une réponse
à ces deux questions. D'autant plus lorsque les possesseurs de réplique ne sont
pas perpétuellement joignables.

\paragraph{Core-nebula~\cite{letia2009crdts} :}] propose de contraindre la
topologie réseau afin de rendre la prise de décisions possible. Ainsi, un cœur
décisionnel prend en charge les choix de suppression réelle des objets.  Ce cœur
décisionnel est restreint à un sous-ensemble des membres du réseaux étant
toujours accessibles, les décisions peuvent alors être prises de manière
fiable. Le reste des participants se conforme à ces décisions au risque de
perdre certaines de leurs modifications.
 
Si l'espace consommé par les pierres tombales est trop important pour être
envisagé, et si ni le ramasse-miettes réparti, ni les contraintes sur la
topologie du réseau ne sont possibles, il existe une alternative : une famille
de CRDTs conçue pour le type séquence et dont le bon fonctionnement ne nécessite
pas de référencer directement d'autres identifiants. En cela, ils évitent
l'usage des pierres tombales mais font face à des problèmes concernant la
complexité spatiale de leurs identifiants.

\subsubsection{Identifiants de taille variable}

Certaines structures de données sans résolution de conflits pour séquences
utilisent des identifiants dont la taille est variable à la
génération~\cite{andre2013supporting, preguica2009commutative,
  weiss2009logoot}. Ainsi, les identifiants sont toujours uniques et immuables
une fois générés, mais leur structure contient une liste d'éléments encodant
leur position relative dans la séquence.  Contrairement aux approches basées sur
les pierres tombales, ces identifiants ne dépendent pas d'autres identifiants
afin d'être intégrés. À ce titre, les suppressions ne se contentent pas de
masquer les éléments, mais les retirent entièrement de la structure. En
revanche, la liste d'éléments constituant les identifiants est susceptible de
grandir, et par là même, de diminuer les performances du systèmes.


\paragraph{Chemins.}

Les identifiants de taille variable peuvent être représentés comme la
concaténation d'éléments basiques (e.g. des entiers). La séquence en résultant
peut être représentée grâce à une structure d'arbre où les éléments de la
séquence sont stockés sur les nœuds et où les arrêtes sont étiquetées de telle
sorte qu'un chemin de la racine jusqu'au nœud forme l'identifiant de
l'élément. Par exemple, un caractère dont l'identifiant serait [3.1] serait
accessible en suivant l'arrête étiquetée 3, puis l'arrête étiquetée 1. Plus
formellement, la séquence est un arbre où chaque nœud peut contenir une valeur,
i.e., un élément (dans l'alphabet $\mathcal{A}$) de la séquence. L'arbre est un
ensemble de paires $\langle \mathcal{P}\subset \{N\}^*,\, \mathcal{A} \rangle$,
i.e., chaque élément est associé à un chemin. De plus, un ordre total
$(\mathcal{P},\, <_\mathcal{P})$ permet d'ordonner les chemins et de retrouver
l'ordre des éléments de la séquence. Notation : un chemin composé de $e$ arrêtes
étiquetées $\ell_1,\,\ell_2,\ldots,\ell_e$ est noté
$[\ell_1.\ell_2\ldots\ell_e]$.

\begin{figure}
  \centering
  \subfloat[Un arbre est l'union de ses identifiants]
  [\label{repl:fig:treeexample}L'arbre représentant la séquence est
  construit grâce à l'union des identifiants et utilise principalement les
  chemins pour ordonner ses caractères.]
  {\input{input/replication/figtreeexample.tex}}
  \hspace{20pt}
  \subfloat[Les désambiguateurs interviennent lorsqu'un chemin identique a été
  alloué]
  [\label{repl:fig:disexample}L'arbre utilise les désambiguateur afin de
  maintenir un état équivalent, même en présence d'insertions concurrentes ayant
  résulté en des chemins identiques. Par soucis de simplicité, seuls les
  désambiguateurs des caractères \texttt{E}, \texttt{R}, et \texttt{T}
  sont affichés.]
  {\input{input/replication/figdisexample.tex}}
  \caption[Arbres contenant une séquence répliquée]
  {Arbres contenant la séquence \texttt{QWERTY}.}
\end{figure}

La figure~\ref{repl:fig:treeexample} montre l'arbre d'arité maximale 10
représentant la séquence. Un auteur insère les caractères \texttt{QWTY} les uns
à la suite des autres résultant sur les chemins [1], [2], [4], et [8]
respectivement. L'insertion du caractère \texttt{E} entre les paires
$\langle [2],\, \texttt{W} \rangle$ et $\langle [4],\, \texttt{T} \rangle$
engendre la paire suivante : $\langle [3],\, \texttt{E} \rangle$. Pour insérer
le caractère \texttt{R}, l'arbre doit être agrandi afin d'accueillir le nouveau
chemin entre \texttt{E} et \texttt{T}. Le chemin en résultant est [3.1]. Insérer
un nouveau caractère entre \texttt{E} et \texttt{R} résulterait en une autre
augmentation de la profondeur de l'arbre. Le chemin serait [3.0.$X$] où
$0<X<10$. L'ordre total $(\mathcal{P},\, <_\mathcal{P})$ permet de retrouver la
séquence \texttt{QWERTY}.


\paragraph{Désambiguation des cas concurrents.}

L'ordre des chemins $(\mathcal{P},\, <_\mathcal{P})$ est un ordre total
lorsqu'un seul auteur écrit. Toutefois, cela devient un ordre partiel lorsque
plusieurs auteurs sont impliqués dans l'édition. Par exemple, si deux auteurs
insèrent un caractère au même endroit dans le document, au même moment, le même
chemin pour les deux caractères risque d'être alloué. Dans ce cas, l'ordre des
caractères n'est pas strictement défini et peut rompre la propriété de
convergence des répliques. Les désambiguateurs utilisent des marqueurs unique de
manière globale pour fournir un ordre total même en présence d'éditions
concurrentes. Ces marqueurs comprennent couramment un identifiant de site unique
associé à une horloge de Lamport~\cite{lamport1978time}. Chaque paire
$\langle element,\, path\rangle$ est associée à un désambiguateur.

Soit l'ensemble des identifiants $\mathcal{I}$ composés tels que
$\mathcal{I} : \mathcal{P} \times \mathcal{A} \times \mathcal{D}$. La
composition de l'ordre partiel $(\mathcal{P},\,<_\mathcal{P})$ et l'ordre total
des désambiguateurs $(\mathcal{D},\, <_\mathcal{D})$ permet d'ordonner les
éléments de la séquence de manière identique quelle que soit la réplique.

La figure~\ref{repl:fig:disexample} montre l'arbre contenant 6 éléments mais
seulement 5 chemins distincts. Tout d'abord, le premier collaborateur $c_1$
insère \texttt{QW}. Ensuite, les collaborateurs $c_1$ et $c_2$ insèrent en
concurrence les caractères \texttt{E} et \texttt{T}, respectivement. Dans les
deux cas, le chemin en résultant est $[3]$. Pour résoudre cette ambiguïté, le
désambiguateur $\langle c_1,\, 3 \rangle$ est associé au caractère \texttt{E};
le désambiguateur $\langle c_2,\, 1 \rangle$ est associé au caractère
\texttt{T}. Recouvrer l'ordre des éléments consiste simplement à comparer, à
chaque niveau de l'arbre, le chemin du niveau, puis l'identifiant de la
réplique, puis l'horloge. Dans cet exemple, le caractère \texttt{E} précède le
caractère \texttt{T} car $c_1< c_2$. Ensuite, le collaborateur $c_1$ insère
\texttt{Y} à la fin de la séquence. Enfin, il insère \texttt{R} entre \texttt{E}
et \texttt{T}. Puisque ces derniers ont un chemin identique, l'espace est
insuffisant entre ces deux chemins pour insérer un nouveau caractère. La
profondeur de l'arbre doit augmenter. La fonction d'allocation doit choisir un
chemin $[3.X]$ tel que $0<X<10$. En copiant le désambiguateur de \texttt{E} au
premier niveau, cela assure que le nouvel identifiant suivra celui du caractère
\texttt{E} et précédera celui du caractère \texttt{T}. Il est important de noter
que les collaborateurs ne choisissent pas les désambiguateurs. Ainsi, la
séquence de cet exemple aurait pu être \texttt{QWTREY} auquel cas une correction
aurait été nécessaire. De plus, la complexité spatiale de ces désambiguateurs
est bornée par leur chemin respectif. Par conséquent, le reste de ce chapitre se
concentre sur ces identifiants.

% Nous définissons le modèle suivant : le CRDT est un arbre $T$ initialisé vide
% équippé des opérations d'insertion $\textsc{insert}$ et de suppression
% $\textsc{delete}$. Un identifiant dans $\mathcal{I}$ contient un chemin dans
% $\mathcal{P}$, un désambiguateur dans $\mathcal{D}$, et un élément dans
% l'alphabet $\mathcal{A}$. L'union des identifiants non supprimés crée l'arbre
% $T$ où chaque noeud possède au plus un élément.  En utilisant un ordre total
% $(\mathcal{I},\, <_\mathcal{I})$, l'arbre est transformé en séquence d'éléments.

% Un chemin est une liste d'entiers dont la taille borne celle du désambiguateur :
% une liste constituée de paires avec l'identifiant unique du serveur hébergeant
% la réplique, et un compteur local à cette réplique (cf. l'exemple des CRDTs pour
% compteurs §\ref{repl:subsubsec:crdts}). La complexité de l'identifiant dépend donc
% essentiellement de l'allocation du chemin dans l'arbre.

\paragraph{Choisir le bon chemin.} La composante la plus critique des approches
pour les séquences où les identifiants sont de taille variable consiste à
choisir les chemins. L'algorithme~\ref{repl:algo:general} montre les
instructions générales de telles approches. Il divise les opérations --
insertion et suppression -- entre la partie locale et la partie distante du
schéma de réplication optimiste. Le cœur de l'algorithme est situé dans la
partie locale de l'opération d'insertion où le chemin et le désambiguateur
doivent être créés. La fonction \textsc{convert2Path} se débarrasse de la partie
désambiguateur des identifiants en argument pour n'en garder que les chemins,
transformés si nécessaire. Lorsqu'il n'y a pas de marques d'opérations
concurrentes, les chemins sont simplement retournés tels quels. Dans le cas
contraire, cette fonction convertit les identifiants en chemins préservant
l'ordre $(\mathcal{P}, <_\mathcal{P})$. Par exemple, dans la
figure~\ref{repl:fig:disexample}, le résultat de l'appel à la fonction
\textsc{convert2Path} avec les identifiants du caractère \texttt{E} et du
caractère \texttt{T} est la paire $\langle [3.0],\, [3.9] \rangle$. La fonction
\textsc{allocPath} alloue un nouveau chemin entre ces bornes. \textsc{allocDis}
décore le chemin pour garantir que l'identifiant -- en tant que composition d'un
chemin, d'un élément, et d'un désambiguateur -- est bien positionné entre les
identifiants qui ont servi à le créer selon la relation d'ordre
$(\mathcal{I},\, <_\mathcal{I})$.

\begin{algorithm}[h]
  \input{input/replication/algogeneral.tex}
  \caption[Séquences avec identifiants de taille variable]
  {\label{repl:algo:general}Séquences avec identifiants de taille variable.}
\end{algorithm}

La fonction \textsc{allocPath} choisit le chemin dans l'arbre entre deux autres
chemins $p$ et $q$ tels que $p$ précède $q$ ($p <_\mathcal{P} q$). Le nouveau
chemin $n$ est positionné entre ces bornes
($p <_\mathcal{P} n <_\mathcal{P} q$). La fonction \textsc{allocPath} doit
choisir parmi les plus petits chemins disponibles afin de conserver de bonnes
performances.

\begin{figure}
  \begin{center}
  \subfloat[Allocation quasi-optimale]
  [\label{repl:fig:allocpathexampleA}Allocation presque optimale]
  {\input{input/replication/figallocpathexampleA.tex}}
  \hspace{30pt}
  \subfloat[Allocation pire-cas]
  [\label{repl:fig:allocpathexampleB}Allocation pire cas]
  {\input{input/replication/figallocpathexampleB.tex}}
  \end{center}
  \caption[Une stratégie d'allocation contre les comportements d'édition] {Une
    même stratégie d'allocation face à des comportements d'édition différents.}
\end{figure}

Les figures~\ref{repl:fig:allocpathexampleA} et~\ref{repl:fig:allocpathexampleB}
illustrent les difficultés rencontrées lors de l'allocation des chemins
composant les identifiants. Dans les deux cas, la fonction d'allocation utilise
la stratégie suivante : la branche la plus à gauche avec la plus petite
profondeur possible. Dans les deux cas, la séquence finale est
\texttt{QWERTY}. Toutefois, les lettres ne sont pas insérées dans un ordre
identique. Dans le premier cas, \texttt{Q} est insérée à l'indice 0, suivie de
\texttt{W} à l'indice 1, suivie de \texttt{E} à l'indice 2 etc.  Dans le second
cas, la lettre \texttt{Y} est insérée à l'indice 0, suivie de \texttt{T} à
l'indice 0 qui, par effet de bord, décale le \texttt{Y} à l'indice 1. La
séquence en résultant est donc \texttt{TY}. L'insertion du \texttt{R} en
position 0 décale toutes lettres de droite etc.

Dans le premier cas (cf. figure~\ref{repl:fig:allocpathexampleA}), l'opération
d'insertion (\texttt{Q}, 0) est transformée en \textsc{insert}($\vdash$,
\texttt{Q}, $\dashv$). Par conséquent, le chemin doit être alloué entre les
bornes virtuelles [0] et [9]. Puisque la stratégie d'allocation consiste à
réserver la branche la plus à gauche et de plus petite taille, le chemin
résultant est [1]. Ensuite, l'opération (\texttt{W}, 1) est transformée en
\textsc{insert}($i_Q$, \texttt{W}, $\dashv$) résultant sur le chemin [2] etc.
Dans ce cas, la profondeur de l'arbre n'augmente jamais. À cet égard, la
stratégie employée est très efficace. Cependant, elle n'est pas totalement
optimale puisque l'arbre est prévu pour accueillir 8 identifiants lorsque
seulement 6 sont alloués.

Dans le second cas (cf. figure~\ref{repl:fig:allocpathexampleB}), l'opération
d'insertion (\texttt{Y}, 0) est transformée en \textsc{insert}($\vdash$,
\texttt{Y}, $\dashv$) dont le résultat est le chemin [1]. Lors de l'insertion
(\texttt{T}, 0), un chemin est requis entre la borne virtuelle du début de
séquence [0] et la borne du caractère \texttt{Y} : [1]. Ainsi, la profondeur du
chemin doit augmenter de telle sorte que le nouvel identifiant muni de l'ordre
total $(\mathcal{I},\,<_\mathcal{I})$ soit placé entre les deux. Considérons un
ordre lexicographique, le chemin résultant est [0.$X$] où $X$ est choisi entre 0
et 10. Suivant la stratégie, le chemin est [0.1] pour la lettre \texttt{T}. Puis
[0.0.1] pour la lettre \texttt{R} etc. La taille des chemins alloués augmente
très rapidement.  La stratégie d'allocation s'avère inefficace dans ce cas.

Cet exemple montre à quel point l'ordre d'insertion des éléments affecte la
longueur des chemins alloués. Malheureusement, ni la séquence d'édition, ni sa
taille ne sont connues par avance.  Passer d'indices locaux mutables et optimaux
d'une séquence classique à des identifiants non-mutable de taille variable d'une
séquence répliquée a un coût qu'il est nécessaire d'analyser afin de proposer
une fonction d'allocation efficace.

\paragraph{Logoot~\cite{weiss2010collaborative, weiss2009logoot,
    weiss2010logootundo} :} Ce CRDT représente originellement ses identifiants
sous forme de liste sans les factoriser sous forme d'arbre. Cette représentation
possède l'avantage de fournir un accès instantané à ses éléments au prix d'une
consommation en espace élevée. En effet, une opération locale effectuée sur la
séquence $\textsc{insert}(element,\, index)$ se traduisant sur la réplique par
$\textsc{insert}(id_{pr\acute{e}cedent},\, element,\, id_{suivant})$ s'effectue
en temps constant. D'un autre coté, les identifiants possèdent des chemins dont
chaque élément est un entier encodé sur 64 bits correspondant à une arité de
$2^{64}$ dans le modèle d'arbre. Un chemin dans $\mathcal{P}$ est donc une
succession d'entiers compris entre 0 et $(2^{64}-1)$ :
$\mathbb{N}_{<2^{64}}.\mathbb{N}_{<2^{64}}\ldots\mathbb{N}_{<2^{64}}$.  L'ordre
total utilisé pour recouvrer la séquence d'éléments est un ordre
lexicographique. Ayant fait l'assomption que les documents étaient édités de
gauche à droite, la stratégie s'avère inefficace lorsque le comportement
d'édition va à l'opposé de cette hypothèse. Le pire cas est déjà illustré dans
la figure~\ref{repl:fig:allocpathexampleB}. La complexité spatiale de chaque
identifiant est linéaire, en résulte une complexité quadratique par rapport à la
taille du document.

\noindent Une extension nommée \textbf{Logoot split}~\cite{andre2013supporting}
étend Logoot lui offrant la possibilité d'adapter la granularité de l'élément
ciblé.  Cette extension prend pour granularité la chaîne de caractère avec la
liberté de la scinder si besoin est. Le nombre d'identifiants à allouer s'en
trouve diminué, et par conséquent, le trafic généré également.

\paragraph{Treedoc~\cite{letia2009crdts, preguica2009commutative} :} Cette
approche représente le document sous forme d'arbre binaire avec parcours infixe.
  
\begin{figure*}
  \begin{center}
    % \subfloat[Augmentation rapide de la taille des chemins alloués par Treedoc]
    % [Augmentation rapide de la taille des chemins alloués par Treedoc]
    % {\input{input/replication/treedocexampleA.tex}}
    % \hspace{10pt}
    % \subfloat[Optimisation dans Treedoc]
    % [Optimisation pour l'édition de gauche à droite dans Treedoc]
    % {\input{input/replication/treedocexampleB.tex}}      
    \input{input/replication/figtreedocexample.tex}
    \caption[Chemins alloués par Treedoc]
    {\label{repl:fig:treedocexample}Exemple de séquence dont les chemins sont
      alloués grâce à Treedoc.}
  \end{center}
\end{figure*}

\noindent La figure~\ref{repl:fig:treedocexample} montre un exemple de
séquence. Si l'on considère un élément \texttt{W} dont le chemin est [], alors
un élément \texttt{Q} dont le chemin est [0] précède \texttt{W}, et un élément
\texttt{E} dont le chemin est [1] succède \texttt{W}. En d'autres termes,
suffixer le chemin d'un 0 signifie \emph{à gauche de}, et suffixer le chemin
d'un 1 signifie \emph{à droite de}. Pour la séquence \texttt{QWERTY} de cet
exemple, le caractère \texttt{Y} obtient le chemin [1.1.1.1].
  
\noindent Tout comme l'approche Logoot, les observations effectuées sur un
corpus Wikipédia montre l'importance d'une fonction d'allocation gérant
l'édition de gauche à droite. Elles conduisent à proposer une heuristique selon
laquelle des nœuds de l'arbre sont virtuellement créés en prévoyance des
éditions à venir. Toutefois, le problème demeure lorsque le comportement
d'édition va à l'encontre de la stratégie créée. L'identifiant peut être de
taille linéaire comparée à la taille du document.


La section suivante s'attache à mettre en évidence les défaillances des
approches n'utilisant pas de pierres tombales. À cet effet, elle se sert de
traces extraites de Wikipédia et de documents créés artificiellement. Enfin,
elle statue le problème scientifique auquel nous nous attaquons.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../paper"
%%% End:
