

\section{État de l'art}
\label{repl:sec:stateoftheart}

Cette section commence par décrire le schéma de réplication optimiste de
séquences -- un document pouvant être représenté par une séquence de caractères
(cf. §\ref{repl:subsec:optimistic}).  Ensuite, cette section passe en revue deux
familles d'approches appartenant à la réplication optimiste des séquences : les
transformées opérationnelles (cf. §\ref{repl:subsec:ot}) et les structures de
données répliquées sans conflits (cf. §\ref{repl:subsec:crdts}). Cette section
s'attache particulièrement à cette dernière famille et en détaille les
représentants.

\subsection{Réplication optimiste de séquences}
\label{repl:subsec:optimistic}

La réplication optimiste~\cite{demers1987epidemic, johnson1975maintenance,
  ladin1992providing, saito2005optimistic} de séquence est un paradigme de
réplication consistant à appliquer les modifications directement sur une
réplique locale de la séquence.  Ainsi, un document est toujours disponible et
réactif aux changements effectués. Ensuite, les modifications sont disséminées
aux autres serveurs hébergeant une réplique où elles sont intégrées. 

Sun et al.~\cite{sun1998achieving} déclarent que l'édition collaborative temps
réel nécessite un système préservant les trois propriétés :
\begin{itemize}
\item Convergence : les répliques ayant reçues les même opérations convergent
  vers un état identique;
\item Causalité : si une opération précède une autre
  opération~\cite{lamport1978time}, alors l'intégration de cette première
  opération précède l'intégration de cette seconde opération;
\item Intention : l'effet observé sur le document lors de la génération d'une
  opération doit être également observé lors de son intégration malgré l'
  interférence d'opérations concurrentes.
\end{itemize}

\noindent La convergence fait l'objet de critère de cohérence à part entière
tels que la cohérence à terme~\cite{bailis2013eventual}, ou la cohérence forte à
terme~\cite{shapiro2011conflict}. Ces critères de cohérence sont très faibles
mais ont beaucoup de succès ces dernières années avec, par exemple, les bases de
données réparties~\cite{dynamo, riak, cassandra, mongodb}. Malheureusement, ces
critères sont trop expressifs : l'état de convergence n'est pas spécifié. Par
exemple, ils permettent aux répliques de converger vers un état arbitraire
n'ayant aucun lien avec les modifications apportées par les participants. À ce
titre, ces critères seuls sont insuffisants pour l'édition collaborative.

\noindent La causalité contraint l'ordre d'intégration des opérations. Ainsi,
une opération dépendante d'une autre opération effectuée avant se trouve
forcément intégrée à sa suite. C'est une manière de forcer l'exécution correcte
de cette première opération : le contexte d'exécution est le même que sur la
réplique d'origine donc le résultat est le même.  
% Malheureusement, capturer
% toutes les relations causales s'avère
% coûteux~\cite{charronbost1991concerning}. Pour chaque participant ayant jamais
% effectué une modification sur le document, une valeur entière doit être
% conservée dans un vecteur. Ce vecteur indique les opérations visibles lors de
% l'exécution de cette opération.  
De même que pour la convergence, baser l'édition collaborative seulement sur un
ordre causal ne fonctionne pas : les opérations concurrentes n'ont pas de
comportement défini.

\noindent Lorsque les définitions des propriétés de convergence et de causalité
font consensus, l'intention des opérations d'une séquence demeure plus difficile
à formaliser dans le cas général. L'effet d'une opération doit respecter le plus
possible sa spécification séquentielle~\cite{bieniusa2012brief}. La
spécification séquentielle d'une séquence inclue deux opérations : l'insertion
d'un élément à une position dans la séquence et la suppression d'un élément à
une position dans la séquence. L'intention semble donc liée à la position des
éléments dans la séquence. Contre cette intuition, nous soutenons qu'une
séquence se définie simplement par un ordre dense sur ses éléments : les
éléments sont ordonnés et il est toujours possible d'insérer un élément entre
deux autres éléments.

Nous distingue la complexité spatiale de la réplique, la complexité en
communication des messages, la complexité temporelle d'une opération générée
localement, la complexité temporelle de l'intégration d'une opération
reçue. Parmi ces complexités, la complexité en communication est la plus
critique et doit être sous-linaire pour passer à l'échelle. En ce qui concerne
les complexités temporelles, il est plus important d'améliorer l'intégration que
la génération car chaque opération locale effectuée conduit à $N$ intégrations,
où $N$ est le nombre de répliques.

Le reste de cette section présente les approches appartenant à la réplication
optimiste de séquences. Les approches à transformées opérationnelles cherchent à
garantir les trois propriétés au prix du passage à l'échelle. Les approches à
structure de données proposant des opérations commutatives s'attachent à la
convergence et à l'intention.


% \paragraph{Cohérence à terme~\cite{bailis2013eventual} :} Lorsque toutes les
% modifications ont été reçues et intégrées par toutes les répliques, celles-ci
% possèdent un état équivalent.

% \noindent Puisque ``\emph{toutes} les modifications'' constitue un ensemble peu
% réaliste pour raisonner sur une exécution réelle, une définition plus précise
% porte sur un sous-ensemble de ces modifications :

% \paragraph{Cohérence forte à terme~\cite{shapiro2011conflict} :} Les répliques
% ayant reçu et intégré les mêmes modifications possèdent un état équivalent.

% \noindent Hélas, ce critère de cohérence est trop expressif : l'état de
% convergence n'est pas spécifié. Par exemple, la cohérence forte à terme permet
% aux répliques de converger vers un état arbitraire n'ayant aucun lien avec les
% modifications apportées par les participants.

% \begin{figure*}
%   \centering
%   \subfloat[Modifications concurrentes]
%   [Les serveurs $n_1$ et $n_3$ modifient leur couleur en même temps.]
%   {\input{./input/replication/figoptimisticexampleA.tex}}
%   \hspace{10pt}
%   \subfloat[Plusieurs états possibles]
%   [Les répliques convergent. Plusieurs états de convergence sont possibles.]
%   {\input{./input/replication/figoptimisticexampleB.tex}}
%   \caption[Convergence en réplication optimiste]
%   {\label{repl:fig:optimisticexample} Exemple de réplication optimiste avec
%     modifications concurrentes.}
% \end{figure*}


% Le type de données répliqué doit respecter autant que possible la spécification
% de sa version séquentielle~\cite{bieniusa2012brief}. Pour nous, une séquence est
% un type abstrait proposant deux opérations de modification dont le résultat sera
% propagé au reste des répliques:
% \begin{inparaenum}[(i)]
% \item l'insertion locale d'un élément à une certaine position dans la séquence; 
% \item la suppression locale de l'élément présent à une certaine position dans la
%   séquence.
% \end{inparaenum}
% Concrètement, les éléments sont positionnés dans la séquence suivant un ordre
% dense, i.e., les éléments sont ordonnées et il est toujours possible d'insérer
% un élément entre deux autres éléments. Lorsqu'une réplique reçoit une opération
% d'insertion, le nouvel élément est ajouté de telle sorte que l'ordre dense entre
% les éléments ayant servi à son insertion locale est préservé. Lorsqu'une
% réplique reçoit une opération de suppression, l'élément à la position ciblé dans
% l'ordre dense est supprimé et l'ordre des éléments ayant servi à sa suppression
% locale est préservé. \TODO{Review.}


% Cependant, résoudre les cas concurrents reste à la charge des développeurs. La
% figure~\ref{repl:fig:optimisticexample} montre un exemple où les répliques
% concernent une couleur. Le serveur $n_1$ souhaite une couleur bleu tandis que
% $n_3$ souhaite une couleur blanche. Après échange, une infinité d'états
% convergeants sont possibles. Par exemple, l'état (i) et (ii) privilégient une
% seule des modifications. L'état (iii) tente de réconcilier les deux
% modifications en mélangeant les couleurs pour obtenir un bleu plus clair. L'état
% (iv) est un état arbitraire sans signification réelle. Tous ces choix respectent
% la cohérence forte à terme, même celui de l'état arbitraire.

% Ce type de cohérence charge le développeur d'un poids énorme quant au bien fondé
% de l'état convergeant.  Récemment, de nombreux efforts ont été fournis afin de
% proposer des bases de données avec cohérence à terme~\cite{dynamo, riak,
%   cassandra, mongodb}, ainsi que des langages sur lesquels
% raisonner~\cite{conway2012logic, meiklejohn2015lasp}.

\subsection{Transformées opérationnelles}
\label{repl:subsec:ot}

Les approches basées sur les transformées opérationnelles
(OT)~\cite{sun1998operational, sun2009contextbased} sont les plus anciennes et
s'appliquent à un large champs d'applications telles que l'édition de textes ou
l'édition d'images. Pour l'édition de textes, les opérations locales d'insertion
et de suppression proposées possèdent une signature correspondant exactement à
la signature commune des séquences : $\textsc{insert}(element,\, position)$ et
$\textsc{delete}(position)$. Lors de la réception d'une opération, ses arguments
sont ajustés afin qu'ils s'appliquent à l'état courant de la réplique malgré les
opérations effectuées et intégrées en concurrence. Cette phase d'intégration
nécéssite l'examen des opérations concurrentes afin d'en compenser les effets
sur la séquence.

% En d'autres termes, le résultat d'une opération locale est l'opération
% elle-même. En revanche, son intégration nécessite l'examen des opérations
% concurrentes afin de compenser les changements sur l'ordre des éléments lors de
% son exécution locale.

\begin{figure}
  \centering
  \input{./input/replication/figotexample.tex}
  \caption[Exemple de transformées opérationnelles] {\label{repl:fig:otexample}
    Exemple de scenario impliquant des transformées opérationnelles. L'opération
    de suppression du premier caractère sur la réplique 3 est transformée afin
    de supprimer le second caractère sur les autres répliques.}
\end{figure}

La figure~\ref{repl:fig:otexample} illustre le principe de fonctionnement des
approches basées sur OT sur un scénario impliquant une séquence répliquée. Dans
cet exemple, les répliques sont toutes initialisées avec la séquence
\texttt{WERTY}. Ensuite, tandis que la première réplique insère le caractère
\texttt{Q} en tête de séquence pour obtenir \texttt{QWERTY}, la troisième
réplique supprime son premier caractère correspondant au \texttt{W}. Lorsque la
réplique 1 reçoit cette dernière opération de suppression, elle est interprétée
comme une opération dont le contexte d'exécution n'avait pas encore intégré
l'insertion du caractère \texttt{Q}. Le décalage d'une position vers la droite
de chaque caractère n'avait donc pas encore été intégré. Par conséquent,
l'argument de l'opération voit sa cible changée aux second caractères :
\texttt{W}.  Réciproquement, la réplique 3 intègre l'insertion de la réplique 1
: l'insertion et la suppression sont détectées concurrentes, toutefois aucune
transformation n'est nécessaire. À terme, les répliques convergent vers la
séquence \texttt{QERTY}. Sans transformation, la réplique 1 aurait obtenu la
séquence \texttt{WERTY} et la propriété de convergence du système aurait été
bafouée.

% Dans le cadre de l'édition de textes, en plus des usuelles opérations
% d'insertion et de suppression, OT fournit des opérations ciblant les chaînes de
% caractères telles que le déplacement, ou le couper -- coller. Toutefois,
% l'analyse de correction nécessite d'examiner chaque couple d'opérations ainsi
% que leurs arguments. En conséquence, lors de l'écriture du
% papier~\cite{imine2003proving}, peu d'approches étaient réellement
% correctes. \TODO{Keep it or not?}

Dans les approches OT décentralisées~\cite{sun2009contextbased}, chaque client
est aussi un serveur hébergeant une réplique de la séquence. Chacune de ces
entités doit être en mesure d'effectuer les transformations d'elle-même. Parmi
les pré-requis à cette tâche figure le mécanisme de détection de concurrence. En
effet, retrouver le contexte d'exécution revient à transformer l'opération reçue
contre toutes celles qui ont été intégrées sans avoir connaissance de cette
première. Cependant, chaque message doit transporter un vecteur d'horloges
(\emph{vector clock})~\cite{lamport1978time} ou de contexte pour chaque
opération. Par conséquent, la complexité en communication est au minimum
linéaire par rapport au nombre de répliques. De plus, ces vecteurs et leur
opération associée sont ensuite sauvegardés dans un historique. La complexité
spatiale est au minimum linéaire selon les deux dimensions : nombre de répliques
et nombre d'opérations. Enfin, la génération d'une opération s'exécute en temps
constant. Cependant, son intégration s'exécute en temps quadratique comparé au
nombre d'opérations concurrentes à l'opération intégrée. Cette répartition des
coûts d'opération est malheureuse car 1 opération locale efficace correspond à
$N$ exécutions distantes potentiellement lente, où $N$ est le nombre de
répliques recevant l'opération. Pour ces raisons, les approches OT
décentralisées ne passent pas à l'échelle. Du reste, dans un environnement bien
maîtrisé, où les opérations arrivent très rapidement à un groupe raisonnable de
participants, ces approches décentralisées sont extrêmement
efficaces~\cite{mehdi2014merging}.

\subsection{Structure de données répliquée sans conflits}
\label{repl:subsec:crdts}

Les structures de données répliquées sans conflits
(CRDTs)~\cite{shapiro2011comprehensive, shapiro2011conflict} appartiennent au
schéma de réplication optimiste. Ces approches sont basées sur des structures de
données abstraites fournissant des opérations dont les résultats commutent par
nature. Les répliques convergent donc vers un état identique même en cas de
concurrence. Contrairement aux approches OT, les opérations concurrentes n'ont
pas besoin d'être détectées. Les CRDTs s'affranchissent donc de la nécessité de
joindre un vecteur d'horloges à chaque opération. Sans cette contrainte, les
CRDTs ont l'opportunité de passer à l'échelle. Contrairement aux approches OT,
la signature des opérations est différente des séquences \og classiques \fg et
correspond à l'intention telles que nous la définissons où une séquence est un
ensemble d'éléments muni d'un ordre dense : les éléments sont ordonnés et il est
toujours possible d'insérer un élément entre deux autres éléments. Par exemple,
\og insérer l'élément $e$ à la position $i$ \fg devient \og insérer l'élément
$e$ entre l'élément en position $i-1$ et l'élément en position $i$ \fg.

Pour fonctionner , les CRDTs pour séquences surchargent chaque élément d'une
métadonnée nommée identifiant. Les identifiants, uniques et immuables,
permettent d'assurer un ordre total (convergence) sur les éléments tout en
respectant un ordre dense (intention) établi lors de l'exécution locale de
l'insertion. Par exemple, si l'élément $e$ est inséré entre l'élément $p$ et
l'élément $q$, alors il n'existe aucune réplique où l'intégration de cette
opération résulterait en une séquence où $e$ n'est pas placé -- directement ou
non -- entre $p$ et $q$.  Si $p$ ou $q$ n'existe(nt) plus car supprimé(s), alors
l'intégration de $e$ doit tout de même respecter l'ordre dense établi lors de
l'insertion de $p$ et $q$. Par exemple, si $o$ précède $p$ dans la séquence mais
que $p$ est supprimé, alors $o$ précède -- directement ou non -- l'élément $e$.

Selon la manière dont les identifiants sont générés, nous distinguons les
approches dont les identifiants référencient des identifiants adjacents à
l'insertion des approches dont les identifiants sont générés à partir des
identifiants adjacents dans un ensemble muni d'un ordre dense. Ces premières
approches recourent à des marqueurs nommés \og pierre tombales \fg lorsqu'une
suppression est effectuée; ces dernières approches n'utilisent pas de pierres
tombales mais des identifiants dont la taille, définie à la génération, varie.
Le reste de cette section s'attache à les présenter.

\subsubsection{Pierres tombales}

Une pierre tombale est une marque laissée après la suppression d'un élément
indiquant qu'un jour, celui-ci a existé à cet emplacement. Bien entendu, ces
marques sont cachées à l'utilisateur et n'apparaissent que dans la structure
sous-jacente. L'impact sur les performances à l'intrégation des opérations en
reste néanmoins présent.

\paragraph{WOOT~\cite{oster2006data} :} Le premier représentant historique des
CRDTs pour séquences suivi par deux extensions
\textbf{WOOTO~\cite{weiss2007wooki}} et
\textbf{WOOTH~\cite{ahmed2011evaluating}}. Dans cette approche chaque
identifiant fait référence aux identifiants voisins à l'insertion.  Lorsqu'ils
sont rassemblés, les identifiants peuvent être ordonnés grâce à un diagramme de
Hasse. Toutefois, cet ordonnancement requiert des deux bornes adjacentes
qu'elles soient
\begin{inparaenum}[(i)]
\item déjà intégrées et
\item toujours présentes.
\end{inparaenum}
%D'où les suppressions réelles impossibles.

\begin{figure}
  \centering
  \input{input/replication/figwootexample.tex}
  \caption[Diagramme de Hasse dans WOOT]
  {\label{repl:fig:wootexample}Le diagramme de Hasse du modèle WOOT représentant
    la séquence \texttt{QWERTY}. Bien que supprimé, le caractère \texttt{Z} est
    indispensable au bon ordonnancement de la séquence.}
\end{figure}

\noindent La figure~\ref{repl:fig:wootexample} illustre la nécessité de
conserver les pierres tombales. Elle montre le diagramme de Hasse généré lors du
scénario suivant. Tout d'abord, un utilisateur écrit \texttt{AZERTY}. Ensuite,
les deux premiers caractères sont supprimés afin d'être remplacés par les
caractères \texttt{QW}. La séquence finale est \texttt{QWERTY}. Toutefois, les
identifiants ne sont pas modifiables, et l'identifiant du caractère \texttt{E}
référence l'identifiant de \texttt{Z}, lui-même référençant l'identifiant de
\texttt{A}. Par conséquent, supprimer complètement les identifiants de
\texttt{A} et/ou de \texttt{Z} revient à rendre l'identifiant de \texttt{E} non
positionnable, et tout ceux qui en dépendent par transitivité.

\paragraph{Causal tree~\cite{grishchenko2010deep} :} Cette approche caractérise
explicitement les relations causales grâce à une représentation sous forme
d'arbre. Ainsi, chaque opération est accompagnée de l'identifiant de la dernière
opération observée. En parcourant l'arbre et en appliquant les opérations, la
séquence peut être retrouvée. Toutefois, les identifiants sont des horloges
vectorielles dont la taille devient élevée. De plus, il est nécessaire de
conserver tous les nœuds de cet arbre causal au cas où une opération y ferait
référence.

\paragraph{Partial persistent sequence~\cite{wu2010partial} :} Cette approche
définit les identifiants dans l'ensemble des nombres rationnels auxquels est
ajoutée une limite quant à leur précision. Hélas, cette limite contraint la
taille maximale que peut atteindre un document. Sans cette troncature,
l'approche serait susceptible d'appartenir à l'autre famille de CRDTs pour
séquence.

\paragraph{Replicated growable array~\cite{roh2011replicated} :} Cette structure
représente la séquence sous forme de liste supportant les opérations
concurrentes. Une table de hachage apporte un accès rapide aux éléments grâce à
leurs identifiants. Les éléments incluent une référence au voisin qu'ils
précèdent lors de leur insertion. Toutefois, pour ne jamais briser la chaîne
ainsi construite, les éléments supprimés sont cachés et restent présents dans la
structure. Une variante sous forme d'arbre a récemment été
proposée~\cite{attiya2016specification}.

\paragraph{String-wise~\cite{yu2012stringwise} :} Cette approche cible
principalement les chaînes de caractères pouvant être subdivisées lors
d'opérations jusqu'à devenir une série de caractères. Les identifiants
référencent alors les chaînes adjacentes à l'insertion ainsi que les autres
éléments de la chaînes si subdivision il y a. 
%% De la même manière que pour les approches précédentes, les références rendent
%% les suppressions réelles impossibles.

\paragraph{DiCE~\cite{conway2014language} :} Cet éditeur concentre
principalement ses efforts sur les garanties de confluence de la
séquence. Chaque identifiant référence le voisin qu'il précède à
l'insertion. L'ordre des éléments est alors fonction de ces relations de
positionnement relatif, et de causalité.

Pour préserver l'ordre dense défini lors de l'exécution locale de l'insertion,
toutes ces approches génèrent des identifiants qui référencient au moins l'un
des identifiants adjacent. Il devient impossible de supprimer un élément de la
structure répliquée sans mettre en danger l'ordre dense à préserver. Ainsi, les
suppressions conservent tous les éléments, qu'ils soient supprimés ou non du
document.  Un document peut être vide bien que la séquence répliquée possède des
milliers d'éléments cachés. La mémoire consommée par ces approches croît au
moins linéairement comparé au nombre d'insertions faites sur la séquence. Plus
problématique : cette croissance est monotone.  Les pierres tombales dégradent à
jamais les performances de l'intégration des opérations où l'ordre des éléments
doit être retrouvé.

Purger la structure de données des éléments cachés est une solution potentielle
aux dégradations de performances. Un mécanisme de ramasse-miettes
réparti~\cite{abdullahi1998garbage} permet de nettoyer une structure de données
en vidant de la mémoire les objets qui ne sont plus accessibles par le
programme, ni localement ni à distance. Ainsi, supprimer réellement un élément
de la séquence revient à s'interroger : \og Est-ce que
\begin{inparaenum}[(i)]
\item toutes les répliques ont supprimé l'élément et
\item tous les éléments référençant l'élément supprimé ont été intégrés
  localement ?
\end{inparaenum}\fg Cela va sans dire qu'il est difficile d'apporter une réponse
à ces deux questions. D'autant plus lorsque les répliques ne sont pas
perpétuellement accessibles. La \emph{core-nebula}~\cite{letia2009crdts} propose
de contraindre la topologie réseau afin de rendre la prise de décisions
possible. Ainsi, un cœur décisionnel prend en charge les choix de suppression
réelle des objets.  Ce cœur décisionnel est restreint à un sous-ensemble des
membres du réseaux étant toujours accessibles. Les décisions peuvent alors être
prises de manière fiable. Le reste des participants se conforme à ces décisions
au risque de perdre certaines de leurs modifications.
 
Un autre famille de CRDTs conçue pour le type séquence et dont le bon
fonctionnement ne nécessite pas de référencer directement d'autres
identifiants. En cela, ils évitent l'usage des pierres tombales mais font face à
des problèmes concernant la complexité spatiale de leurs identifiants.

\subsubsection{Identifiants de taille variable}

Contrairement aux approches basées sur les pierres tombales, certains CRDTs
génèrent des identifiants ne référenciant pas d'autres identifiants. Par
conséquent, ces identifiants sont indépendants : leur intégration ne nécessite
pas l'intégration d'autres identifiants. Ces identifiants ont une taille
variable définie à la génération~\cite{andre2013supporting,
  preguica2009commutative, weiss2009logoot}.  Ainsi, les identifiants sont
toujours uniques et immuables une fois générés, mais leur structure est une
liste de valeurs encodant la position relative de l'élément par rapport aux
positions relatives des éléments adjacents à son insertion. Ces identifiants
sont directement créés dans un ensemble muni d'un ordre total pour assurer la
convergence, et muni d'un ordre dense pour assurer l'intention. À ce titre, ces
approches constituent une implémentation directe de notre spécification
séquentielle des séquences.

% Contrairement aux approches basées sur les pierres tombales, ces identifiants
% sont indépendents : leur intégration ne dépend pas des autres identifiants. À ce
% titre, les suppressions ne se contentent pas de masquer les éléments mais les
% retirent entièrement de la structure. En revanche, la liste de valeurs
% constituant les identifiants est susceptible de grandir, et par là même, de
% diminuer les performances du système.

\paragraph{Logoot~\cite{weiss2010collaborative, weiss2009logoot,
    weiss2010logootundo} :} Ce CRDT représente la séquence sous forme de liste
d'identifiants. Chacun des identifiants est une liste de triples notée
$id = [t_1,\,t_2,\,\ldots,\,t_k]$ où $t_k=\langle p_k,\,s_k,\,c_k \rangle$ où
$p_k$ est un entier positif, $s_k$ est un identifiant unique de site, et $c_k$
est un compteur local au site $s_k$. Un ordre lexicographique est utilisé pour
préserver un ordre total parmi les éléments :
\begin{align*}
  t_i < t_j \iff & (p_i < p_j) \vee \\
                 & ((p_i = p_j) \wedge (s_i<s_j)) \vee \\
                 & ((p_i = p_j) \wedge (s_i = s_j) \wedge (c_i < c_j)) \\
  t_i = t_j \iff & \neg (t_i < t_j) \wedge \neg (t_j < t_i) \\
  id_i <_\mathcal{I} id_j \iff & \exists (m > 0)(\forall n < m),\, (t^i_n = t^j_n) \wedge (t^i_m < t^j_m) \\
  id_i =_\mathcal{I} id_j \iff & \forall m,\, t^i_m = t^j_m
\end{align*}
L'identifiant unique de site est obtenu lors de la création de la réplique. Le
compteur est incrémenté à chaque insertion locale dans la séquence. Ne reste
comme seul facteur de choix à disposition de Logoot : l' entier $p$ présent dans
chaque triple. Lors de la $x$\up{ème} insertion locale par le site $s_y$, les
identifiants adjacents à la position d'insertion sont récupérés. Ainsi
l'identifiant $id$ du nouvel élément inséré en position $i$ doit respecter
$id_{i-1}<_\mathcal{I} id <_\mathcal{I} id_i$. Par transitivité
$\ldots id_{i-2} <_\mathcal{I} id_{i-1} <_\mathcal{I} id <_\mathcal{I} id_{i+1}
<_\mathcal{I} id_{i+2} \ldots$.
Prenons pour exemple, $id_{i-1}=[\langle 12,\,s_1,\,c_1\rangle]$ et
$id_{i}=[\langle 12,\, s_1,\,c_1\rangle.\langle 1337,\, s_2, c_2\rangle]$. Pour
choisir les valeurs successives de $p$ du nouvel identifiant, Logoot commence
par examiner chaque niveau des identifiants adjacents afin de connaitre la
taille du nouvel identifiant. Ici, les identifiants commencent tous les deux
avec l'entier $12$.  Puisqu'entre $12$ et $12$ aucune valeur entière n'est
disponible, Logoot doit chercher plus loin dans les identifiants. L'un d'eux ne
possède pas de second triplet ce qui correspond implicitement à
$\langle 0,\, -\infty ,\, -\infty \rangle$.  Entre $0$ et $1337$ de nombreuses
valeurs sont disponibles.  Logoot doit choisir parmi toutes ces valeurs laquelle
constituera définitivement le nouvel identifiant. Ce choix impactera également
sur l'allocation des identifiants à venir.
%% et ne doit pas être pris à la légère.
Des observations effectuées sur un corpus de documents
\emph{Wikipedia}~\cite{wikipedia} suggère qu'allouer un identifiant proche de
l'identifiant précédent est une meilleure stratégie afin de conserver des
identifiants de petite taille.  Ici, Logoot choisit donc une valeurs proche de
$0$ et compose le nouvel identifiant en copiant une partie des données présentes
dans les identifiants adjacents. Par exemple,
$id = [\langle 12,\, s_1,\,c_1 \rangle.\langle 10,\,s_y, x\rangle]$.  En
utilisant l'ordre lexicographique définit auparavant, nous obtenons bien
$id_{i-1} <_\mathcal{I} id <_\mathcal{I} id_i$.

\noindent Logoot favorise, par son choix d'entier proche de l'identifiant
précédent la position d'insertion, les comportements d'édition où les éléments
sont insérés de gauche à droite. Toutefois, lorsque le comportement d'édition va
à l'encontre de cette stratégie, la taille des identifiants peut grimper
extrêmement rapidement. La complexité spatiale de chaque identifiant est
linéaire comparé au nombre d'insertions dans le document, et puisque chaque
identifiant est disséminé aux autres répliques, la complexité en communication
en hérite. De plus, les valeurs choisies par Logoot dans les identifiants sont
toujours comprises entre $0$ et $2^{64}$. Cette constance implique que, même
dans le cadre d'un comportement d'édition attendu, la complexité est linéaire
(mais fortement atténuée). Là encore, le trafic généré en souffre directement.

\noindent La représentation de la séquence sous forme de liste possède
l'avantage de fournir un accès instantané à ses éléments. Ainsi, la traduction
de \og insérer l'élément $e$ à la position $i$ \fg à \og insérer l'élément $e$
ente l'identifiant $id_{i-1}$ de l'élément en position $i-1$ et l'identifiant
$id_i$ de l'élément en position $i$ \fg s'effectue en temps constant.
Cependant, cette rapidité d'accès est seulement possible au détriment d'une
consommation en espace élevée : Logoot ne profite pas de la redondance
d'informations sur les triplets. La complexité spatiale de la structure est
quadratique comparée au nombre d'insertions effectuées dans la séquence.

\noindent Une extension nommée \textbf{Logoot split}~\cite{andre2013supporting}
étend Logoot lui offrant la possibilité d'adapter la granularité de l'élément
ciblé.  Cette extension prend pour granularité la chaîne de caractères avec la
liberté de la scinder si besoin est. Le nombre d'identifiants à allouer s'en
trouve diminué, et par conséquent, le trafic généré également.

\paragraph{Treedoc~\cite{letia2009crdts, preguica2009commutative} :} Cette
approche représente le document sous forme d'arbre binaire avec parcours infixe.
Lorsqu'il n'y a pas de concurrence, chaque nœud de l'arbre possède au plus un
élément et au plus 2 fils. Les arêtes de l'arbre sont étiquetées par la valeur
binaire 0 ou 1.  Si un nœud possède un élément et deux fils, tous les éléments
du sous-arbre accessible par l'arête dont l'étiquette est 0 se trouvent à gauche
de ce premier élément; tous les éléments du sous-arbre accessible par l'arête
dont l'étiquette est 1 se trouve à droite de ce premier élément. Du fait de la
concurrence, chaque nœuds peut aussi devenir un super-nœud acceuillant plusieurs
nœuds. De plus, chaque nœuds est décoré d'un identifiant unique de site et d'un
compteur local à ce site. Ainsi, les nœuds inclus dans chaque super-nœuds
suivent eux aussi un ordre total. Un identifiant est donc une liste de triples
$id = [t_1.t_2\ldots t_k]$ où $k$ est un entier, et
$t_k = \langle b_k,\, s_k,\, c_k\rangle$ où $b_k$ est une valeur binaire, $s_k$
est un identifiants unique de site, et $c_k$ est un compteur local au site
$s_k$.  Prenons par exemple les éléments adjacents
$id_{i-1}=[\langle 0,\,s_1,\,c_1 \rangle.\langle 1,\,s_1,\,c_2 \rangle]$ et
$id_i=[\langle 0,\,s_1,\,c_1 \rangle.\langle 1,\,s_1,\,c_2 \rangle. \langle 1,\,
s_2,\, c_3 \rangle]$.
Lors de la $x$\up{ème} insertion locale par le site $s_y$, Treedoc examine les
identifiants adjacents à la position d'insertion. Treedoc commence par examiner
si un identifiant est l'ancêtre direct de l'autre, i.e., la liste de triples
d'un identifiant est inclue dans la liste de triples de l'autre identifiant. Par
exemple, $id_{i-1}$ est l'ancêtre de $id_i$. Dans ce cas, Treedoc copie
l'identifiant du descendant et le suffixe par $\langle 1,\, s_y,\, x \rangle$ si
le descendant précède la position d'insertion; $\langle 0,\, s_y,\, x \rangle$
dans le cas contraire. Si aucun des identifiants n'est l'ancêtre de l'autre,
Treedoc choisit de copier l'identifiant précédant la position d'insertion et lui
suffixe le triple $\langle 1,\, s_y,\, x \rangle$.

\noindent Tout comme l'approche Logoot, les observations effectuées sur un
corpus de documents Wikipédia montrent l'importance d'une stratégie d'allocation
gérant l'édition de gauche à droite. Elles conduisent à proposer une heuristique
selon laquelle des nœuds de l'arbre sont virtuellement créés en prévoyance des
éditions à venir. Toutefois, de manière identique à Logoot, lorsque le
comportement d'édition va à l'encontre de cette stratégie, les identifiants sont
de taille linéaire comparée à la taille du document.

\noindent La représentation de la séquence sous forme d'arbre possède l'avantage
de factoriser les nombreux triples communs composants les identifiants
Treedoc. Cette forme compacte de structure à le défaut de ne pas permettre
d'accès direct aux identifiants. Retrouver les identifiants adjacents à la
position d'insertion requière un parcours de l'arbre. De plus, cette
représentation compacte n'a pas d'incidence sur les identifiants
eux-même. Puisque chaque identifiant doit être disséminé individuellement aux
autres répliques, le trafic généré demeure inchangé.

Les CRDTs fonctionnant avec des identifiants de taille variable n'utilisent pas
de pierre tombales lors de la suppression d'éléments. Par conséquent, la mémoire
consommée par ces approches n'est pas strictement croissante. Un document vide
signifie que la séquence répliquée est également vide. En revanche, les
identifiants peuvent croître de manière linéaire par rapport au nombre
d'insertions dans le document. Malheureusement, la complexité en communication
hérite de cette progression. De même, les opérations d'insertions subissent des
baisses de performances. 

Une solution consiste à relocaliser les identifiants. En d'autres termes, les
identifiants sont modifiés au profit d'identifiants plus courts et conservant
l'ordre dense des éléments de la séquence. Toutefois, supprimer puis réinsérer
l'ensemble des éléments dans un document neuf ne suffit pas : le trafic engendré
est élevé et un tel processus effectué en concurrence est susceptible de clôner
les éléments. Il faut donc parvenir à prendre une décision globale sur la
relocalisation ce qui revient à obtenir un consensus en contexte réparti. Les
consensus sont coûteux à obtenir dans les systèmes à large échelle où le nombre
de répliques est grand, et particulièrement lorsque ces répliques ne sont pas
accessibles en permanence.

Afin d'éviter les baisses de performances ainsi que les mécanismes de
relocalisation, une autre solution consiste à obtenir des identifiants
suffisamment courts pour qu'ils ne nécessite pas d'être relocalisé. La section
suivante s'attache à décrire les difficultés liées à l'allocation d'identifiants
à taille variable.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../paper"
%%% End:
