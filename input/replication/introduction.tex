
\lettrine{L}es éditeurs Web tels que Google Docs~\cite{googledocs} ou
ShareLaTeX\cite{sharelatex} ont fortement contribué à l'adoption des éditeurs
collaboratifs par le grand public~\cite{mogan2010impact}. Des millions
d'utilisateurs partagent et rédigent leurs documents en temps réel directement
dans leurs navigateurs Web. Cependant un serveur central appartenant à un
fournisseur de services sert d'intermédiaire à l'édition. Cela soulève des
problèmes en termes de confidentialité, de censure, de propriété et
d'intelligence économique~\cite{cherrueau2016composer, gellman2013us,
pearson2011toward}. À cela s'ajoutent des problèmes de tolérance aux pannes et
de passage à l'échelle, notamment en ce qui concerne le nombre
d'utilisateurs. Bien que les petits groupes de collaborateurs soient la cible
principale de ce genre d'application, certains événements de plus ample
dimension tels que les cours en ligne ouverts et massifs
(\emph{MOOC})~\cite{breslow2013studying} nécessitent de supporter des groupes à
la fois plus larges et plus dynamiques. En effet, si un cours commence avec
quelques milliers d'étudiants prenant des notes, sa population diminue en
fonction de l'intérêt qu'il suscite, avant de récupérer certains étudiants
désireux de réussir leurs examens. Google Docs gère les groupes de grande
taille. En revanche, seuls les $50$ premiers collaborateurs ont le droit de
modifier le document en temps réel, les suivants voient leur accès limité à la
simple lecture. Selon nous, même si seulement un petit ensemble parmi les
millions de collaborateurs est réellement en train d'écrire, n'importe quel
participant de la session d'édition devrait pouvoir lire et écrire lorsqu'il le
souhaite.

La décentralisation des éditeurs collaboratifs constitue une étape nécessaire
vers une solution aux problèmes liés à la confidentialité : un document doit
réellement appartenir à ceux qui le rédigent. Cependant, les problèmes de
passage à l'échelle demeurent. Résoudre ces problèmes revient à trouver un bon
compromis entre la complexité en communication, en espace et en temps de
l'éditeur. En particulier, obtenir une complexité en communication sous-linéaire
par rapport au nombre de participants est crucial pour gérer les groupes de
grande envergure.

Afin d'augmenter la réactivité aux changements et la disponibilité des
documents, les éditeurs temps réel actuels emploient le schéma de réplication
optimiste~\cite{demers1987epidemic, ladin1992providing, saito2005optimistic,
sun1998achieving} de séquences -- les documents étant simplement représentés par
des séquences de caractères. En tant que tel, chaque éditeur
\begin{enumerate}[(i)] 
\item héberge une copie locale du document. L'évolution de la mémoire prise par
cette copie constitue la complexité spatiale de l'approche;

\item modifie directement cette copie locale. L'évolution des performances des
 opérations de modification constitue la complexité temporelle à la génération
 de l'approche;

\item propage le résultat de ses opérations à tous les éditeurs impliqués dans
la rédaction du document. L'évolution du nombre et de la taille des messages
disséminés constitue la complexité en communication de l'éditeur;

\item reçoit les messages et intègre leur contenu sur sa propre
réplique. L'évolution des performances de l'intégration de ces opérations de
modification constitue la complexité temporelle à l'intégration de l'approche.
\end{enumerate}

\noindent La réplication optimiste fait l'hypothèse d'une dissémination fiable
des messages, i.e., tous les éditeurs reçoivent l'intégralité des messages. Le
système est correct si les répliques intégrant un même ensemble d'opérations
convergent vers un état équivalent, i.e., les collaborateurs lisent un même
document~\cite{bailis2013eventual, shapiro2011conflict}.

Les algorithmes décentralisés appartenant aux transformées opérationnelles
(\emph{OT})~\cite{sun1998operational, sun2009contextbased} transportent dans
chaque message un vecteur d'état ou de contexte dans le but de détecter les
opérations concurrentes. La taille de ces vecteurs croît linéairement avec le
nombre de membres ayant jamais participé à l'édition du document. Ainsi, ces
approches sont efficaces pour les petits groupes d'utilisateurs mais ne sont pas
adaptées aux groupes de plus large dimension, plus dynamiques, et sujet aux
aléas du réseau -- notamment sur la latence.

Les structures de données répliquées sans conflits
(\emph{CRDTs})~\cite{burckhardt2014replicated, shapiro2011comprehensive,
shapiro2011conflict}, contrairement aux approches OT, ne payent pas le prix de
la détection de la concurrence entre les opérations. Toutefois, ils transportent
des identifiants uniques et immuables pour chaque opération propagée sur le
réseau. La taille de ces identifiants a un impact direct sur le trafic généré.
Deux classes de CRDTs conçues pour les séquences existent :

\paragraph{Pierre tombales~\cite{ahmed2011evaluating, attiya2016specification,
conway2014language, grishchenko2010deep, oster2006data, roh2011replicated,
weiss2007wooki, wu2010partial, yu2012stringwise}.} Les CRDTs tels que
WOOT~\cite{oster2006data} transportent un identifiant de taille constante.  
%La complexité en communication est donc excellente. 
Toutefois, les éléments supprimés sont simplement cachés à l'utilisateur tout en
restant présents dans la structure. La consommation en espace de la réplique
croît inexorablement.
%Les opérations deviennent moins performantes.
%Pour alléger la réplique, il devient nécessaire de la purger de ses pierres tombales. 
Pour réellement détruire les éléments supprimés, l'exécution périodique d'un
ramasse-miettes réparti~\cite{abdullahi1998garbage} est
nécessaire. Malheureusement, cela ne passe pas à
l'échelle~\cite{abdullahi1998garbage}.

\paragraph{Identifiants de taille variable~\cite{andre2013supporting,
 preguica2009commutative, weiss2009logoot}.} Les CRDTs tels que
Logoot~\cite{weiss2009logoot} ne nécessitent pas de pierres tombales mais
transportent des identifiants de taille variable. En fonction de la stratégie
d'allocation, ces identifiants peuvent croître linéairement par rapport au
nombre d'insertions effectuées dans le document. Puisque chaque identifiant doit
être envoyé à l'ensemble des répliques, la complexité en communication s'en
trouve directement impactée. Pour équilibrer la structure \emph{a posteriori},
l'exécution périodique d'un mécanisme de relocalisation~\cite{letia2009crdts}
est nécessaire. Malheureusement, dans notre contexte, atteindre un tel consensus
s'avère très coûteux~\cite{mostefaoui2015signature}.

\textbf{Afin d'éviter tout protocole additionnel de relocalisation des
identifiants, comment allouer des identifiants de taille variable dont la taille
soit directement sous-linéaire ?}

Ce chapitre présente \LSEQ~\cite{nedelec2013concurrency, nedelec2013lseq}, une
fonction d'allocation d'identifiants dont la taille croît de manière
polylogarithmique par rapport au nombre d'insertions dans la séquence. À ce
titre, elle évite l'utilisation de protocoles de relocalisation.
%% et, par conséquent, passe à l'échelle.

La section~\ref{repl:sec:stateoftheart} présente l'état de l'art. Elle introduit
le schéma de réplication optimiste des séquences avant d'en détailler les
approches ainsi que les limites auxquelles elles sont assujetties.  La
section~\ref{repl:sec:problem} définit le problème scientifique à résoudre. La
section~\ref{repl:sec:proposal} présente \LSEQ, une approche basée sur les
opérations commutatives dont la complexité est sous-linéaire. La
section~\ref{repl:sec:complexity} s'attache à démontrer cette complexité ainsi
que les conditions sous lesquelles elle s'applique. La
section~\ref{repl:sec:validation} valide \LSEQ au travers de simulations. La
section~\ref{repl:sec:conclusion} conclut ce chapitre.


%%% Local Variables:
%%% mode: plain-tex
%%% TeX-master: "../../paper"
%%% End:
