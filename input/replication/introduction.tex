
\lettrine{L}es éditeurs web tels que \emph{Google Docs}~\cite{googledocs} ou
\emph{ShareLaTeX}\cite{sharelatex} ont fortement contribué à l'adoption des
éditeurs collaboratifs par le public~\cite{mogan2010impact}. Des millions
d'utilisateurs partagent et rédigent leurs documents en temps réel directement
dans leur navigateur web. Cependant un serveur central appartenant à un
fournisseur de services sert d'intermédiaire à l'édition. Cela soulève des
problèmes en termes de confidentialité, de censure, et d'intelligence
économique~\cite{cherrueau2016composer, gellman2013us, pearson2011toward}. À
cela s'ajoutent des problèmes de passage à l'échelle, notamment en ce qui
concerne le nombre d'utilisateurs. Bien que les petits groupes de collaborateurs
soient la cible principale de ce genre d'application, certains événements de
plus ample dimension tels que les cours en ligne ouverts et massifs
(\emph{MOOC})~\cite{breslow2013studying} nécessitent de supporter des groupes à
la fois plus larges et plus dynamiques. En effet, si un cours commence avec
quelques milliers d'étudiants prenant des notes, sa population diminue en
fonction de l'intérêt qu'il suscite, avant de récupérer certains étudiants
désireux de réussir leurs examens. \emph{Google Docs} gère les groupes de grande
taille. En revanche, seuls les $50$ premiers collaborateurs ont le droit
d'écrire ensemble en temps réel, les suivants voient leurs accès limités à la
simple lecture du document. Selon nous, même si seulement un petit ensemble
parmi les millions de collaborateurs est réellement en train d'écrire, n'importe
quel participant de la session d'édition devrait pouvoir lire et écrire
lorsqu'il le souhaite.

Les éditeurs décentralisés autorisant l'édition en temps réel n'ont pas besoin
de serveurs intermédiaires. Par conséquent, ils résolvent les problèmes liés à
la confidentialité. Toutefois les problèmes de passage à l'échelle
demeurent. Résoudre ces problèmes revient à trouver un bon compromis entre les
complexités en communication, en espace et en temps. Par dessus tout, obtenir
une complexité en communication sous-linéaire comparée au nombre de participants
est crucial pour gérer les groupes de grande taille.

Afin d'augmenter la réactivité aux changements et la disponibilité des
documents, les éditeurs temps réel utilisent la réplication
optimiste~\cite{demers1987epidemic, ladin1992providing, saito2005optimistic,
sun1998achieving} de séquences -- les documents étant simplement des séquences
de caractères. En tant que tel, chaque éditeur héberge une copie locale d'un
document. L'évolution de la mémoire prise par cette copie constitue la
complexité spatiale de l'approche. Chaque modification est directement appliquée
sur cette copie avant d'être propagée aux autres répliques où elle est
intégrée. Ainsi, la complexité temporelle des opérations de modification se
trouve divisée entre une partie locale et une partie distante. La complexité en
communication intervient lors de la propagation des changements au système. Le
système est correct si les répliques intégrant un même ensemble d'opérations
convergent vers un état équivalent, i.e., les utilisateurs lisent un même
document~\cite{bailis2013eventual, shapiro2011conflict}.

Les algorithmes décentralisés appartenant aux transformées opérationnelles
(\emph{OT})~\cite{sun1998operational, sun2009contextbased} transportent un
vecteur d'état ou de contexte dans le but de détecter les opérations
concurrentes. Ces vecteurs croissent linéairement en comparaison du nombre de
membres ayant jamais participé à l'édition du document. Ainsi, ces approches
sont efficaces pour les petits groupes d'utilisateurs mais ne sont pas adaptées
aux groupes de plus large dimension, plus dynamiques, et sujet aux aléas du
réseau -- notamment sur la latence.

Les structures de données répliqués sans  conflits
(\emph{CRDTs})~\cite{burckhardt2014replicated, shapiro2011comprehensive,
shapiro2011conflict}, contrairement aux approches OT, ne payent pas le prix de
la détection de concurrence entre les opérations. Toutefois, ils transportent
des identifiants uniques et immuables pour chaque opération propagée sur le
réseau. La taille de ces identifiants a un impact direct sur le trafic généré.
Deux classes de CRDTs conçues pour les séquences existent :

\paragraph{Pierre tombales~\cite{ahmed2011evaluating, attiya2016specification,
conway2014language, grishchenko2010deep, oster2006data, roh2011replicated,
weiss2007wooki, wu2010partial, yu2012stringwise}.} Les CRDTs tels que
WOOT~\cite{oster2006data} transportent un identifiant de taille constante. La
complexité en communication est donc excellente. Toutefois, les éléments
supprimés sont simplement cachés à l'utilisateur. La consommation en espace de
la réplique croît inexorablement. Les opérations deviennent moins
performantes. Pour alléger la réplique, il devient nécessaire de la purger de
ses pierres tombales. Cette purge reviendrait à exécuter un protocole de
ramasse-miettes réparti~\cite{abdullahi1998garbage} qui ne passe pas à
l'échelle~\cite{abdullahi1998garbage}.

\paragraph{Identifiants de taille variable~\cite{andre2013supporting,
 preguica2009commutative, weiss2009logoot}.} Les CRDTs tels que
Logoot~\cite{weiss2009logoot} ne nécessitent pas de pierres tombales mais
transportent des identifiants dont la taille varie à la génération. En fonction
de la stratégie d'allocation, ces identifiants peuvent croître linéairement
comparé au nombre d'insertions effectuées dans le document. Puisque chaque
identifiant doit être envoyé à l'ensemble des répliques, la complexité en
communication s'en trouve directement impactée.  Équilibrer la structure
reviendrait à exécuter un protocole de consensus qui ne passe pas à
l'échelle~\cite{mostefaoui2015signature}.

\textbf{Afin d'éviter tout protocole additionnel de relocalisation des
identifiants, comment allouer des identifiants de taille variable dont la taille
soit directement sous-linéaire ?}

Ce chapitre présente \LSEQ~\cite{nedelec2013concurrency, nedelec2013lseq}, une
fonction d'allocation d'identifiants dont la taille croît de manière
polylogarithmique par rapport au nombre d'insertions dans la séquence. À ce
titre, elle évite l'utilisation de protocole de relocalisation et, par
conséquent, passe à l'échelle.

La section~\ref{repl:sec:stateoftheart} présente l'état de l'art. Elle introduit
le schéma de réplication optimiste des séquences avant d'en détailler les
représentants ainsi que les limites auxquelles ils sont asujetis.  La
section~\ref{repl:sec:problem} définit le problème scientifique à résoudre. La
section~\ref{repl:sec:proposal} présente \LSEQ, une approche basée sur les
opérations commutatives dont la complexité est sous-linéaire. La
section~\ref{repl:sec:complexity} s'attache à démontrer cette complexité ainsi
que les conditions sous lesquelles elle s'applique. La
section~\ref{repl:sec:validation} valide \LSEQ au travers de simulations. La
section~\ref{repl:sec:conclusion} conclut ce chapitre.


%%% Local Variables:
%%% mode: plain-tex
%%% TeX-master: "../../paper"
%%% End:
