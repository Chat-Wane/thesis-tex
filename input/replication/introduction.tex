
\lettrine{L}es éditeurs Web tels que \emph{Google Docs}~\cite{googledocs} ou
\emph{ShareLaTeX}\cite{sharelatex} ont fortement contribué à l'adoption des
éditeurs collaboratifs par le grand public~\cite{mogan2010impact}. Des millions
d'utilisateurs partagent et rédigent leurs documents en temps réel directement
dans leurs navigateurs Web. Cependant un serveur central appartenant à un
fournisseur de services sert d'intermédiaire à l'édition. Cela soulève des
problèmes en termes de confidentialité, de censure, de propriété et
d'intelligence économique~\cite{cherrueau2016composer, gellman2013us,
pearson2011toward}. À cela s'ajoutent des problèmes de tolérance aux pannes et
de passage à l'échelle, notamment en ce qui concerne le nombre
d'utilisateurs. Bien que les petits groupes de collaborateurs soient la cible
principale de ce genre d'application, certains événements de plus ample
dimension tels que les cours en ligne ouverts et massifs
(\emph{MOOC})~\cite{breslow2013studying} nécessitent de supporter des groupes à
la fois plus larges et plus dynamiques. En effet, si un cours commence avec
quelques milliers d'étudiants prenant des notes, sa population diminue en
fonction de l'intérêt qu'il suscite, avant de récupérer certains étudiants
désireux de réussir leurs examens. \emph{Google Docs} gère les groupes de grande
taille. En revanche, seuls les $50$ premiers collaborateurs ont le droit
d'écrire ensemble en temps réel, les suivants voient leurs accès limités à la
simple lecture du document. Selon nous, même si seulement un petit ensemble
parmi les millions de collaborateurs est réellement en train d'écrire, n'importe
quel participant de la session d'édition devrait pouvoir lire et écrire
lorsqu'il le souhaite.

Les éditeurs décentralisés autorisant l'édition en temps réel n'ont pas besoin
de serveurs intermédiaires. Ils constituent une étape nécessaire vers une
solution aux problèmes liés à la confidentialité. Cependant, le problème du
passage à l'échelle demeure. Résoudre ce problème revient à trouver un bon
compromis entre les complexités en communication, en espace et en temps du
système. Par dessus tout, obtenir une complexité en communication sous-linéaire
comparée au nombre de participants est crucial pour gérer les groupes de grande
envergure.

Afin d'augmenter la réactivité aux changements et la disponibilité des
documents, les éditeurs temps réel actuels emploient le schéma de réplication
optimiste~\cite{demers1987epidemic, ladin1992providing, saito2005optimistic,
sun1998achieving} de séquences -- les documents étant simplement représentés par
des séquences de caractères. En tant que tel, chaque éditeur
\begin{enumerate}[(i)] 
\item héberge une copie locale du document. L'évolution de la mémoire prise par
cette copie constitue la complexité spatiale de l'approche;

\item modifie directement cette copie locale. L'évolution des performances de
ces opérations de modification constitue la complexité temporelle à la
génération de l'approche;

\item propage le résultat de l'opération à tous les éditeurs impliqués dans la
rédaction du document. L'évolution du nombre et de la taille des messages
disséminés constitue la complexité en communication de l'éditeur;

\item reçoit et intègre le message qu'il a reçu sur sa propre
réplique. L'évolution des performances de l'intégration de ces opération de
modification constitue la complexité temporelle à l'intrégation de l'approche.
\end{enumerate}

%  où elle est intégrée. Ainsi, la \textbf{complexité temporelle} des opérations
% de modification se trouve divisée entre une partie \emph{locale} et une partie
% \emph{distante}. La \emph{complexité en communication} intervient lors de la
% propagation des changements au système.

\noindent Le système est correct si les répliques intégrant un même ensemble
d'opérations convergent vers un état équivalent, i.e., les utilisateurs lisent
un même document~\cite{bailis2013eventual, shapiro2011conflict}.

Les algorithmes décentralisés appartenant aux transformées opérationnelles
(\emph{OT})~\cite{sun1998operational, sun2009contextbased} transportent un
vecteur d'état ou de contexte dans le but de détecter les opérations
concurrentes. Ces vecteurs croissent linéairement en comparaison du nombre de
membres ayant jamais participé à l'édition du document. Ainsi, ces approches
sont efficaces pour les petits groupes d'utilisateurs mais ne sont pas adaptées
aux groupes de plus large dimension, plus dynamiques, et sujet aux aléas du
réseau -- notamment sur la latence.

Les structures de données répliqués sans conflits
(\emph{CRDTs})~\cite{burckhardt2014replicated, shapiro2011comprehensive,
shapiro2011conflict}, contrairement aux approches OT, ne payent pas le prix de
la détection de concurrence entre les opérations. Toutefois, ils transportent
des identifiants uniques et immuables pour chaque opération propagée sur le
réseau. La taille de ces identifiants a un impact direct sur le trafic généré.
Deux classes de CRDTs conçues pour les séquences existent :

\paragraph{Pierre tombales~\cite{ahmed2011evaluating, attiya2016specification,
conway2014language, grishchenko2010deep, oster2006data, roh2011replicated,
weiss2007wooki, wu2010partial, yu2012stringwise}.} Les CRDTs tels que
WOOT~\cite{oster2006data} transportent un identifiant de taille constante.  
%La complexité en communication est donc excellente. 
Toutefois, les éléments supprimés sont simplement cachés à l'utilisateur. La
consommation en espace de la réplique croît inexorablement. 
%Les opérations deviennent moins performantes.
%Pour alléger la réplique, il devient nécessaire de la purger de ses pierres tombales. 
Pour réellement détruire les éléments supprimés, l'exécution périodique d'un
ramasse-miettes réparti~\cite{abdullahi1998garbage} est
nécessaire. Malheureusement, cela ne passe pas à
l'échelle~\cite{abdullahi1998garbage}.

\paragraph{Identifiants de taille variable~\cite{andre2013supporting,
 preguica2009commutative, weiss2009logoot}.} Les CRDTs tels que
Logoot~\cite{weiss2009logoot} ne nécessitent pas de pierres tombales mais
transportent des identifiants de taille variable. En fonction de la stratégie
d'allocation, ces identifiants peuvent croître linéairement comparé au nombre
d'insertions effectuées dans le document. Puisque chaque identifiant doit être
envoyé à l'ensemble des répliques, la complexité en communication s'en trouve
directement impactée. Pour équilibrer la structure \emph{a posteriori},
l'exécution périodique d'un mécanisme de relocalisation~\cite{letia2009crdts}
est nécessaire. Malheureusement, dans notre contexte, atteindre un tel consensus
s'avère très coûteux~\cite{mostefaoui2015signature}.

\textbf{Afin d'éviter tout protocole additionnel de relocalisation des
identifiants, comment allouer des identifiants de taille variable dont la taille
soit directement sous-linéaire ?}

Ce chapitre présente \LSEQ~\cite{nedelec2013concurrency, nedelec2013lseq}, une
fonction d'allocation d'identifiants dont la taille croît de manière
polylogarithmique par rapport au nombre d'insertions dans la séquence. À ce
titre, elle évite l'utilisation de protocole de relocalisation.
%% et, par conséquent, passe à l'échelle.

La section~\ref{repl:sec:stateoftheart} présente l'état de l'art. Elle introduit
le schéma de réplication optimiste des séquences avant d'en détailler les
représentants ainsi que les limites auxquelles ils sont asujetis.  La
section~\ref{repl:sec:problem} définit le problème scientifique à résoudre. La
section~\ref{repl:sec:proposal} présente \LSEQ, une approche basée sur les
opérations commutatives dont la complexité est sous-linéaire. La
section~\ref{repl:sec:complexity} s'attache à démontrer cette complexité ainsi
que les conditions sous lesquelles elle s'applique. La
section~\ref{repl:sec:validation} valide \LSEQ au travers de simulations. La
section~\ref{repl:sec:conclusion} conclut ce chapitre.


%%% Local Variables:
%%% mode: plain-tex
%%% TeX-master: "../../paper"
%%% End:
