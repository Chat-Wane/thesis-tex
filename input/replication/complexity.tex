
\section{Analyse en complexité}
\label{repl:sec:complexity}

Dans l'édition de texte, la plupart des comportements d'édition peuvent
empiriquement être résumés à la composition de deux comportements basiques.

\paragraph{Le comportement d'édition aléatoire.} L'auteur insère de nouveaux
éléments à ce qui semble être des positions aléatoires dans la séquence. Par
exemple, ce comportement peut apparaître lors de corrections orthographiques,
e.g. l'auteur écrit \texttt{QWETY} et réalise qu'il lui manque le \texttt{R}. Il
l'ajoute donc dans un second temps;

\paragraph{Le comportement d'édition monotone} L'auteur insère de nouveaux
éléments les uns à la suite des autres (avant ou après l'élément le plus
récemment inséré). Par exemple, lorsqu'un auteur écrit \texttt{QWERTY}, il
commence généralement par le caractère \texttt{Q} jusqu'à arriver au caractère
\texttt{Y}. À l'opposé, les insertions dans un historique se font en tête pour
des raisons pratiques. Ces comportements sont respectivement notés l'édition de
droite à gauche, et l'édition de gauche à droite.

Cette section concentre l'analyse en complexité de \LSEQ sur les comportements
d'édition susmentionnés auxquels est ajouté une analyse en pire cas. Il est
important de noter que le comportement d'édition monotone constitue un cas
défavorable puisqu'il tend à déséquilibrer l'arbre stockant la séquence
répliquée. Aussitôt que les participants commencent à éditer à différents
endroits -- ce qui est plus proche d'un cas d'utilisation réel -- l'arbre
commence à s'équilibrer et les opérations deviennent plus efficaces
proportionnellement. L'analyse ne fait pas mention de cas moyen puisqu'il
nécessite de connaître la distribution des positions d'insertions effectuées par
des être humains ce qui représente une tâche complexe. Enfin, l'analyse en
complexité se concentre sur la représentation de la séquence sous forme
d'arbre. Cette représentation, par rapport à une liste, possède l'avantage d'une
structure de séquences plus compacte au prix d'accès plus lents.  D'autres
structures existent proposant d'autres compromis. Cependant, il est important de
noter que la complexité spatiale d'un identifiant demeure inchangée.

\subsection{Complexité spatiale}
\label{repl:subsec:space}

Dans cette analyse, la complexité spatiale d'un seul identifiant est
différenciée de la complexité spatiale de l'arbre stockant la séquence. La
première est importante puisqu'elle influence directement la complexité en
communication. En effet, chaque identifiant est propagé à tous les possesseurs
de réplique. La seconde est importante puisqu'elle représente le mémoire allouée
localement par chaque éditeur collaboratif.

La section~\ref{repl:sec:proposal} spécifie que chaque nouvelle concaténation
dans le chemin de l'identifiant requière un bit additionnel pour l'encoder. Cela
représente au total $\mathcal{O}(e^2)$ bits pour encoder le chemin, où $e$ est
la profondeur du chemin dans l'arbre. Heureusement, cette profondeur est bornée
selon le comportement d'édition remplissant l'arbre exponentiel. 

\begin{figure}
  \begin{center}
    \subfloat[Arbre \LSEQ rempli par des éditions aléatoires]
    [\label{repl:fig:randomlseqtree}Arbre \LSEQ rempli par des éditions aléatoires.]
    {\input{input/replication/figrandomlseqtree.tex}}
    \hspace{10pt}
    \subfloat[Arbre \LSEQ rempli par des éditions monotones]
    [\label{repl:fig:monotoniclseqtree}Arbre \LSEQ rempli par des éditions monotones.]
    {\input{input/replication/figmonotoniclseqtree.tex}}
    \hspace{10pt}
    \subfloat[Arbre \LSEQ rempli dans le pire cas]
    [\label{repl:fig:worstlseqtree}Arbre \LSEQ rempli dans le pire cas.]
    {\input{input/replication/figworstlseqtree.tex}}
    \caption[Influence des comportements d'édition sur l'arbre exponentiel]
    {Influence des comportements d'édition sur l'arbre exponentiel.}
  \end{center}
\end{figure}


\paragraph{Comportement d'édition aléatoire. } L'édition aléatoire remplit
l'arbre à des positions aléatoires. En conséquence, l'arbre reste équilibré
(cf. figure~\ref{repl:fig:randomlseqtree}). Étant exponentiel, l'arbre peut
stocker $\textstyle\sum\nolimits_{i=1}^{k}{2^{(i^2-i)/2}}$ éléments, où $k$ est
la profondeur de l'arbre. Ainsi, la borne supérieure sur la profondeur des
chemins est $\mathcal{O}(\sqrt{\log I})$ concaténations, où $I$ est le nombre
d'insertions. Puisque les chemins nécessitent $\mathcal{O}(e^2)$ bits pour être
encodés, les chemins ont une complexité spatiale optimale de
$\mathcal{O}(\log I)$. Ce résultat s'applique à toutes les approches utilisant
des identifiants de taille variable~\cite{preguica2009commutative,
  weiss2009logoot}. Toutefois, puisque \LSEQ utilise une structure d'arbre
factorisant les parties communes des identifiants, la complexité spatiale totale
n'est pas la somme des identifiants, mais seulement $\mathcal{O}(I\log I)$.

\paragraph{Comportement d'édition monotone.} L'édition monotone remplit
seulement une branche de l'arbre
(cf. figure~\ref{repl:fig:monotoniclseqtree}). Pourtant, comme l'arité maximale
d'un nœud augmente lorsque sa profondeur augmente, la croissance de l'arbre
ralentit au cours des insertions. Dans ce cas, l'arbre stocke jusqu'à
$2^{e+1}-1$ éléments, où $e$ est la profondeur de l'arbre. Ainsi, le nombre de
concaténation composant le chemin est $\mathcal{O}(\log I)$, où $I$ est le
nombre d'insertions. La représentation binaire des chemins grandissant de façon
quadratique, la complexité spatiale des identifiants est
$\mathcal{O}((\log I)^2)$. Globalement, la complexité spatiale de l'arbre reste
la même, à savoir $\mathcal{O}(I \log I)$.

\paragraph{Pire cas.} Le pire cas s'obtient par l'insertions systématique
d'éléments à l'endroit où l'espace d'allocation est le plus faible. Par exemple,
lorsque la sous-fonction d'allocation employée est conçue pour l'édition de
gauche à droite, peu d'espace est laissé disponible à gauche de ce niveau.  Dans
le pire cas, chaque insertion augmente la profondeur de l'arbre
(cf. figure~\ref{repl:fig:worstlseqtree}). Ainsi, après $I$ insertions, l'arbre
comprend $e$ éléments, où $e$ est la profondeur de l'arbre. Chaque nouveau
chemin possède tous les autres chemins. Ainsi, la complexité spatiale des
identifiants est $\mathcal{O}(I^2)$ et la complexité spatiale de l'arbre est
elle aussi $\mathcal{O}(I^2)$.

\begin{table}
  \begin{center}
    \caption[Bornes supérieures de la complexité spatiale de \LSEQ, Logoot, et
    Treedoc] {\label{repl:table:lseqspace} Bornes supérieures de la complexité
      spatiale de \LSEQ, Logoot, et Treedoc. Où $I$ est le nombre d'insertions
      effectuées sur la séquence.}
    \input{input/replication/tablelseqspace.tex}
  \end{center}
\end{table}

\paragraph{Résumé.} Le tableau~\ref{repl:table:lseqspace} résume les complexités
spatiales de \LSEQ. En particulier, la croissance des identifiants est attendue
entre un logarithme et un polylogarithme. La croissance est donc bien
sous-linéaire comparé au nombre d'insertions effectuées sur la séquence. Pour
atteindre cette amélioration, \LSEQ sacrifie son pire cas en le rendant
quadratique. Toutefois, ce pire cas est rendu difficile à obtenir. En effet, les
deux sous-fonctions d'allocation aux buts antagonistes résolvent leurs
limitations respectives. De plus, si un utilisateur malintentionné tente de
produire ce pire cas, la différence entre la croissance attendue et la
croissance observée serait telle que le coupable serait aisément
identifiable. Des mesures pourraient alors être prises. Le
tableau~\ref{repl:table:lseqspace} montre aussi que, comparé à l'état de l'art,
\LSEQ améliore grandement la taille des identifiants mais voit sa taille globale
légèrement dégradée, i.e., de $\mathcal{O}(I)$ à $\mathcal{O}(I\log I)$. Le
compromis reste avantageux car les communications héritent de l'amélioration sur
les identifiants.

\subsection{Complexité temporelle}

L'analyse en complexité temporelle fournit des indices sur l'évolution des
performances de chaque opération au cours des insertions. Ces opérations sont
découpées entre leur exécution locale et leur exécution distante. Tout comme
pour la complexité spatiale, l'analyse se porte sur les trois comportements
d'édition suivant : aléatoire, monotone, et pire cas.

\paragraph{Insertion locale.} Cette opération consiste simplement à construire
un nouveau chemin en fonction des chemins adjacents. Par conséquent, la
complexité dépend de la taille de ces chemins qui grandissent en fonction du
comportement d'édition. Les comportements aléatoire, monotone, et pire cas
conduisent respectivement à une croissance de l'arbre en
$\mathcal{O}(\sqrt{\log I})$, $\mathcal{O}(\log I)$, et $\mathcal{O}(I)$. La
complexité temporelle de la partie locale de l'insertion suit donc ces
même complexités.

\paragraph{Suppression locale.} L'opération consiste à propager l'identifiant à
supprimer à tous les participants. L'opération se fait donc en temps constant
$\mathcal{O}(1)$ quel que soit le comportement d'édition.

\paragraph{Insertion et suppression distante.} Les opérations d'insertion et de
suppression locales retournent toutes les deux des identifiants que la partie
distante de l'opération correspondante est en charge d'intégrer.  Les
instructions composant ces opérations distantes sont identiques : il s'agit
principalement d'une exploration de l'arbre. Par conséquent, leur complexité
temporelle est identique. Encore une fois, les comportements d'édition
aléatoire, monotone, et pire cas conduisent respectivement à une croissance de
l'arbre exponentiel de l'ordre de $\mathcal{O}(\sqrt{\log I})$,
$\mathcal{O}(\log I)$, et $\mathcal{O}(I)$.  Les fils de chaque nœud de l'arbre
sont ordonnés selon leur chemin. Ainsi, une recherche dichotomique récursive
permet d'atteindre la feuille de l'arbre recherchée. La suppression distante
supprime les nœuds qu'elle traverse si ce nœud ne possède qu'un seul élément
parmi ses sous-arbres. La complexité temporelle de la recherche dichotomique
dépend du niveau $l$ à laquelle elle est effectuée : $\mathcal{O}(\log 2^l)$.
Les recherches à répétition conduisent à une borne supérieure en
$\mathcal{O}(\textstyle\sum\nolimits_{i=1}^{e}(\log 2^i))$ où $e$e est la
profondeur de l'arbre. En remplaçant la variable $e$, les bornes supérieures sur
la complexité temporelle des opérations deviennent
$\mathcal{O}(\log I + \sqrt{\log I})$ pour le comportement aléatoire,
$\mathcal{O}((\log I)^2 + \log I)$ pour le comportement monotone, et
$\mathcal{O}(I)$ dans le pire cas. Pour ce dernier, cela signifie qu'une
comparaison par élément est nécessaire afin d'atteindre la feuille la plus
profonde.

\begin{table}
  \begin{center}
    \caption[Bornes supérieures de la complexité temporelle de \LSEQ]
    {\label{repl:table:lseqtime} Bornes supérieures de la complexité temporelle
      de \LSEQ. Où $I$ est le nombre d'insertions effectuées sur la séquence.}
    \input{input/replication/tablelseqtime.tex}
  \end{center}
\end{table}


\paragraph{Interface arbre -- séquence.} La structure de données répliquée est
un arbre mais l'objet manipulé par l'éditeur collaboratif est une séquence. Il
est donc nécessaire de fournir les fonctionnalités d'accès élémentaires afin de
faire le lien entre l'arbre et la séquence. Un fonction additionnelle de
\textsc{lookup} est requise. Son but est de récupérer l'élément à l'indice
spécifié dans la séquence, et inversement. Puisque la structure sous-jacente est
un arbre, l'accès n'est pas direct.

\noindent Chaque nœud de l'arbre possède un compteur désignant la quantité
d'éléments présents dans ses sous-arbres. Chaque opération d'insertion ou de
suppression met à jour ces compteurs lorsqu'elle explore le chemin. Ensuite,
calculer l'indice d'un identifiant revient à compter le nombre d'éléments chez
les voisins des nœuds explorés, en commençant par l'élément de l'une des
extrémités de l'arbre. Hélas, selon le comportement d'édition, les performances
de cette fonction peuvent se dégrader très rapidement.

\begin{figure}
  \centering
  \input{input/replication/figgetexample.tex}
  \caption[Recherche d'identifiants dans l'arbre] {\label{repl:fig:getexample}
    Exemple de parcours effectué lors de la recherche de l'identifiant en
    position 5 correspondant au caractère \texttt{Y}.}
\end{figure}

\noindent La figure~\ref{repl:fig:getexample} montre un exemple de recherche
d'un identifiant dans un arbre représentant la séquence \texttt{QWERTY}. La
recherche concerne la position $5$ correspondant au caractère \texttt{Y}. Ici,
l'arbre est parcouru en partant du fils gauche de la racine. Ce fils sait que
ses sous-branches contiennent 3 caractères. L'algorithme en déduit que le
prochain fils de la racine est à la position 4. En examinant ce second fils,
l'algorithme déduit que l'identifiant recherché est inclue dans l'un de ses
fils. Ainsi, il continue l'exploration dans ce sous-arbre. Lorsqu'il examine le
nœud contenant \texttt{Y}, il sait que celui-ci est en position $5$. Par
conséquent, il retourne le chemin qu'il a empreinté pour y parvenir, à savoir
[5.4]. Nous pouvons observer dans cet exemple que si la recherche était parti de
la droite, elle n'aurait eu à parcourir qu'un seul élément intermédiaire
(contenant le caractère \texttt{T}), et aurait donc été plus efficace.

\begin{table}
  \begin{center}
    \caption[Bornes supérieures de la complexité temporelle du
    \textsc{lookup} de \LSEQ] {\label{repl:table:lseqlookup} Bornes supérieures
      de la complexité temporelle de la fonction \textsc{lookup} de \LSEQ. Où
      $I$ est le nombre d'insertions effectuées sur la séquence.}
    \input{input/replication/tablelseqlookup.tex}
  \end{center}
\end{table}

\noindent Le comportement d'édition aléatoire conduit à un arbre dont la
profondeur est bornée par $\mathcal{O}(\sqrt{\log I})$. Dans pareil cas, une
très faible portion de l'arbre est explorée. Pour obtenir la borne supérieure,
il faut que le nœud à rechercher se trouve en plein milieu de la séquence, ce
qui force à examiner la moitié des voisins du nœud exploré à chaque niveau de
l'arbre. Puisque chaque nœud peut posséder jusqu'à deux fois plus de fils que
son parent, le nombre de voisins à examiner double également. Au total, la somme
de ces voisins est égale au nombre de nœuds présents dans une branche du plus
profond niveau, c'est-à-dire $\mathcal{O}(2^{\sqrt{\log I}}$ éléments.

\noindent Grâce à un raisonnement identique, la fonction de \textsc{lookup} après
un comportement d'édition monotone -- ce qui constitue le pire cas -- est bornée
par $\mathcal{O}(I)$. En effet, seulement une branche est remplie et
explorée. Ici, le compteur maintenus par chaque nœud devient inutile puisque les
nœuds ne possèdent qu'un seul et unique élément. L'exploration s'achève au plus
profond des niveaux contenant $\mathcal{O}(2^{\log_2 I})$ éléments dont la
moitié doit être examiné. La complexité temporelle dans ce cas est :
$\mathcal{O}(I)$.

\paragraph{Résumé.} Les tableaux~\ref{repl:table:lseqtime}
et~\ref{repl:table:lseqlookup} synthétisent la complexité temporelle des
opérations. L'arbre exponentiel permet d'obtenir des opérations de mise-à-jour
de l'état efficace. En revanche, l'opération \textsc{lookup} qui permet
d'interfacer l'arbre et la séquence souffre de ce choix de structure. Entre
autres, le comportement d'édition monotone constitue le pire cas pour cette
opération où l'accès se fait en temps linéaire. Heureusement, 
\begin{inparaenum}[(i)]
\item la vue n'a pas besoin d'être mise-à-jour si l'indice du nouvel élément se
  trouve hors du champs de visibilité de l'utilisateur. Ainsi, la fonction
  \textsc{lookup} peut s'arrêter plus tôt;
\item un accès rapide aux identifiants alloués le plus récent ainsi que les
  chemins qui lui sont adjacents efface le coût du \textsc{lookup} puisque ces
  accès rapides peuvent être maintenus à jour pendant les insertions sans coût
  additionnel.
\end{inparaenum}

\subsection{Résumé de l'analyse en complexité}

L'analyse en complexité révèle les améliorations apportées par \LSEQ par rapport
à l'état de l'art ainsi que leur coût. Dans le pire cas, la complexité de \LSEQ
est moins bonne que celle de l'état de l'art~\cite{preguica2009commutative,
  weiss2009logoot}.  D'un autre coté, cette concession permet d'améliorer ses
performances sur les autres comportements d'édition considérés plus probables
dans l'édition collaborative. Le résultat le plus important concerne la borne
supérieure sur la complexité spatiale des identifiants, à savoir une croissance
polylogarithmique comparée au nombre d'insertions dans la séquence. L'importance
de ce résultat provient du fait qu'il s'étend à la complexité en communication
de l'application qui l'utilise. En comparaison, les représentants de l'état de
l'art~\cite{preguica2009commutative, weiss2009logoot} fournissent des
identifiants dont la taille croît linéairement par rapport au nombre
d'insertions dans la séquence.  En outre, la complexité spatiale de la structure
ainsi que la complexité temporelle de ses opérations montre que le choix d'un
arbre pour représenter la séquence est efficace. Néanmoins, selon les
préférences, le choix d'un vecteur -- en tant que version aplatie de l'arbre --
est possible afin d'améliorer les performances des opérations au prix d'un usage
mémoire plus important~\cite{weiss2009logoot}. La section suivante s'attache à
valider ces analyses en complexité au travers d'expérimentations.


% \subsubsection{indexOf}
% \label{repl:subsec:indexof}

% \begin{wrapfigure}{r}{0.6\textwidth}
%   \vspace{-35pt} %% (ugly)
%   \begin{minipage}[t]{0.6\textwidth}
%     \begin{algorithm}[H]
%       \input{input/replication/algoindexof.tex}
%       \caption{\label{repl:algo:indexof} indexOf.}
%     \end{algorithm}
%   \end{minipage}
%   \vspace{-15pt}
% \end{wrapfigure}

% L'algorithme~\ref{repl:algo:indexof} présente les instructions de la fonction
% \textsc{indexOf}. Celle-ci sert essentiellement à placer les éléments réçus dans
% la séquence perçue par l'utilisateur.  Celle-ci est divisée en trois :
% \begin{inparaenum}[(i)]
% \item La fonction \textsc{getIndexesOf} retourne les indices successifs dans les
%   listes triées constituants les fils des nœuds de l'arbre. Celle-ci utilise la
%   fonction \textsc{binaryIndexOf} possédant un complexité temporelle
%   logarithmique comparée à la taille du tableau trié parcouru.
% \item La fonction \textsc{getSum} parcours l'arbre afin d'en déduire l'indice de
%   séquence correspondant. Afin de ne pas avoir à parcourir l'entièreté des
%   branches, les nœuds sauvegardent le nombre de sous-branches qu'ils possèdent
%   (similairement à l'algorithme~\ref{repl:algo:get}).  La
%   ligne~\ref{repl:line:optimization} définit la façon dont l'arbre est
%   parcouru. Un optimisation consiste à parcourir l'arbre à partir de la borne la
%   plus proche de l'indice à la profondeur concernée.
% \item La fonction \textsc{indexOf} est composée des deux fonctions
%   susmentionnées.
% \end{inparaenum}

% \TODO{Figure explaining the operation.}

% La complexité temporelle de cette fonction est proche de celle de la fonction
% \textsc{get} car basée sur le même principe. La seule différence est le surcoût
% logarithmique lié à la recherche dichotomique à chaque niveau de l'arbre. Encore
% une fois, les complexités linéaires ne sont pas problématiques car ces
% opérations peuvent être effectuées en arrière-plan. De plus, l'utilisateur
% possède une vue partielle du document. Si les mises à jour ne tombent pas dans
% cette fenêtre, la fonction peut arrêter son éxecution.


% \subsection{Modification de la structure}

% La structure d'arbre représentant le document réparti se modifie au rythme des
% insertions et suppressions effectuées par les utilisateurs, qu'ils soient
% distants ou non. 

% \subsubsection{insert}


% \begin{wrapfigure}{r}{0.6\textwidth}
%   \vspace{-35pt} %% (ugly)
%   \begin{minipage}[t]{0.6\textwidth}
%     \begin{algorithm}[H]
%       \input{input/replication/algoinsert.tex}
%       \caption{\label{repl:algo:insert} Insert.}
%     \end{algorithm}
%   \end{minipage}
%   \vspace{-15pt}
% \end{wrapfigure}

% L'algorithme~\ref{repl:algo:insert} présente les instructions de la fonction
% d'insertion.


% \subsubsection{delete}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../paper"
%%% End:
